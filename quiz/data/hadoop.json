[
    {
        "question": "What is Hadoop primarily used for?",
        "options": [
            "Image Processing",
            "Big Data Processing",
            "Web Development",
            "Database Management"
        ],
        "answer": "Big Data Processing"
    },
    {
        "question": "Why was Hadoop created?",
        "options": [
            "To develop faster web applications",
            "To store and process large datasets efficiently",
            "To improve cloud computing performance",
            "To manage relational databases"
        ],
        "answer": "To store and process large datasets efficiently"
    },
    {
        "question": "Which company initially developed Hadoop?",
        "options": [
            "Google",
            "Yahoo",
            "Facebook",
            "Amazon"
        ],
        "answer": "Yahoo"
    },
    {
        "question": "Which of the following is a key component of the Hadoop ecosystem?",
        "options": [
            "MySQL",
            "HDFS",
            "Docker",
            "Redis"
        ],
        "answer": "HDFS"
    },
    {
        "question": "What was the main inspiration behind Hadoop?",
        "options": [
            "Google's MapReduce and Google File System (GFS)",
            "Amazon's S3 storage",
            "Microsoft's SQL Server",
            "Facebook’s Graph API"
        ],
        "answer": "Google's MapReduce and Google File System (GFS)"
    },
    {
        "question": "Which of the following is NOT a component of Hadoop?",
        "options": [
            "MapReduce",
            "YARN",
            "Spark",
            "HDFS"
        ],
        "answer": "Spark"
    },
    {
        "question": "Which part of Hadoop is responsible for storing large datasets across multiple nodes?",
        "options": [
            "MapReduce",
            "HDFS",
            "YARN",
            "Hive"
        ],
        "answer": "HDFS"
    },
    {
        "question": "What does YARN stand for in Hadoop?",
        "options": [
            "Yet Another Redundant Node",
            "Yet Another Resource Negotiator",
            "Your Application Runtime Network",
            "Yellow And Red Nodes"
        ],
        "answer": "Yet Another Resource Negotiator"
    },
    {
        "question": "Which of the following is NOT a use case of Hadoop?",
        "options": [
            "Processing large datasets",
            "Real-time transaction processing",
            "Data analytics",
            "Machine learning on big data"
        ],
        "answer": "Real-time transaction processing"
    },
    {
        "question": "Which file system does Hadoop use to store large amounts of data?",
        "options": [
            "NTFS",
            "HDFS",
            "FAT32",
            "EXT4"
        ],
        "answer": "HDFS"
    },
    {
        "question": "What type of architecture does Hadoop follow?",
        "options": [
            "Master-Slave",
            "Peer-to-Peer",
            "Client-Server",
            "Monolithic"
        ],
        "answer": "Master-Slave"
    },
    {
        "question": "Which of the following is responsible for running applications in Hadoop?",
        "options": [
            "HDFS",
            "MapReduce",
            "YARN",
            "Spark"
        ],
        "answer": "YARN"
    },
    {
        "question": "Which Hadoop component provides an SQL-like interface to process structured data?",
        "options": [
            "HDFS",
            "Hive",
            "Pig",
            "HBase"
        ],
        "answer": "Hive"
    },
    {
        "question": "What is the default replication factor in HDFS?",
        "options": [
            "1",
            "2",
            "3",
            "4"
        ],
        "answer": "3"
    },
    {
        "question": "Which programming model does Hadoop use for processing data?",
        "options": [
            "MapReduce",
            "Streaming",
            "Multithreading",
            "Batch Processing"
        ],
        "answer": "MapReduce"
    },
    {
        "question": "Which language is Hadoop primarily written in?",
        "options": [
            "Python",
            "Java",
            "C++",
            "Scala"
        ],
        "answer": "Java"
    },
    {
        "question": "Which of the following is a NoSQL database in the Hadoop ecosystem?",
        "options": [
            "MySQL",
            "HBase",
            "PostgreSQL",
            "MongoDB"
        ],
        "answer": "HBase"
    },
    {
        "question": "Which Hadoop component is used for workflow scheduling?",
        "options": [
            "Oozie",
            "Zookeeper",
            "Sqoop",
            "Flume"
        ],
        "answer": "Oozie"
    },
    {
        "question": "Which tool is used to move data from relational databases into Hadoop?",
        "options": [
            "Pig",
            "Hive",
            "Sqoop",
            "HBase"
        ],
        "answer": "Sqoop"
    },
    {
        "question": "Which tool is used for collecting and aggregating log data in Hadoop?",
        "options": [
            "Flume",
            "Kafka",
            "Oozie",
            "Pig"
        ],
        "answer": "Flume"
    },
    {
        "question": "Which of the following is an alternative to MapReduce for data processing in Hadoop?",
        "options": [
            "Spark",
            "YARN",
            "Flume",
            "HBase"
        ],
        "answer": "Spark"
    },
    {
        "question": "Which component acts as a coordinator for distributed applications in Hadoop?",
        "options": [
            "Oozie",
            "Zookeeper",
            "Hive",
            "HBase"
        ],
        "answer": "Zookeeper"
    },
    {
        "question": "Which command is used to check the status of HDFS?",
        "options": [
            "hadoop dfsadmin -report",
            "hadoop fs -ls",
            "hadoop namenode -format",
            "hadoop datanode -status"
        ],
        "answer": "hadoop dfsadmin -report"
    },
    {
        "question": "What is the purpose of Hadoop's secondary NameNode?",
        "options": [
            "It serves as a backup in case the primary NameNode fails",
            "It stores the metadata of NameNode",
            "It performs garbage collection on HDFS",
            "It processes MapReduce jobs"
        ],
        "answer": "It stores the metadata of NameNode"
    },
    {
        "question": "Which of the following describes the function of a DataNode in HDFS?",
        "options": [
            "Stores file system metadata",
            "Manages job scheduling",
            "Stores and retrieves data blocks",
            "Handles user authentication"
        ],
        "answer": "Stores and retrieves data blocks"
    },
    {
        "question": "Which component of Hadoop is responsible for distributing jobs across the cluster?",
        "options": [
            "YARN",
            "MapReduce",
            "HDFS",
            "HBase"
        ],
        "answer": "YARN"
    },
    {
        "question": "Which of the following Hadoop components is responsible for fault tolerance in HDFS?",
        "options": [
            "Replication",
            "Partitioning",
            "Sharding",
            "Load Balancing"
        ],
        "answer": "Replication"
    },
    {
        "question": "In Hadoop, what happens when a DataNode fails?",
        "options": [
            "The entire cluster stops working",
            "The NameNode re-replicates the lost blocks",
            "All the data is lost permanently",
            "A new DataNode is created automatically"
        ],
        "answer": "The NameNode re-replicates the lost blocks"
    },
    {
        "question": "Which of the following is a major advantage of Hadoop?",
        "options": [
            "Supports real-time data processing",
            "Handles large-scale distributed processing efficiently",
            "Runs only on Windows systems",
            "Works only with relational databases"
        ],
        "answer": "Handles large-scale distributed processing efficiently"
    },
    {
        "question": "What is the role of JobTracker in Hadoop 1.x?",
        "options": [
            "Stores metadata of HDFS",
            "Coordinates the execution of MapReduce jobs",
            "Manages data replication",
            "Schedules YARN applications"
        ],
        "answer": "Coordinates the execution of MapReduce jobs"
    },
    {
        "question": "Which command is used to copy files from local storage to HDFS?",
        "options": [
            "hadoop fs -copyFromLocal",
            "hadoop fs -get",
            "hadoop fs -ls",
            "hadoop fs -rm"
        ],
        "answer": "hadoop fs -copyFromLocal"
    },
    {
        "question": "Which of the following best describes a block in HDFS?",
        "options": [
            "The smallest unit of data storage in HDFS",
            "A directory storing multiple files",
            "A compressed file format",
            "A component of NameNode"
        ],
        "answer": "The smallest unit of data storage in HDFS"
    },
    {
        "question": "What is the default block size in Hadoop 2.x?",
        "options": [
            "64 MB",
            "128 MB",
            "256 MB",
            "512 MB"
        ],
        "answer": "128 MB"
    },
    {
        "question": "Which of the following is NOT a Hadoop scheduling algorithm?",
        "options": [
            "FIFO Scheduler",
            "Capacity Scheduler",
            "Fair Scheduler",
            "Round Robin Scheduler"
        ],
        "answer": "Round Robin Scheduler"
    },
    {
        "question": "What is the purpose of speculative execution in Hadoop?",
        "options": [
            "To execute failed tasks automatically",
            "To run slow tasks redundantly for faster execution",
            "To optimize disk usage in HDFS",
            "To reduce the number of map tasks"
        ],
        "answer": "To run slow tasks redundantly for faster execution"
    },
    {
        "question": "Which component of Hadoop facilitates the parallel execution of tasks?",
        "options": [
            "HDFS",
            "MapReduce",
            "Hive",
            "Flume"
        ],
        "answer": "MapReduce"
    },
    {
        "question": "Which of the following is used for real-time data streaming in the Hadoop ecosystem?",
        "options": [
            "Pig",
            "Kafka",
            "Hive",
            "HBase"
        ],
        "answer": "Kafka"
    },
    {
        "question": "Which tool is used for writing and executing MapReduce-like scripts in an easier manner?",
        "options": [
            "Pig",
            "Hive",
            "HBase",
            "Sqoop"
        ],
        "answer": "Pig"
    },
    {
        "question": "Which file format is optimized for read-heavy workloads in Hadoop?",
        "options": [
            "Parquet",
            "CSV",
            "JSON",
            "TXT"
        ],
        "answer": "Parquet"
    },
    {
        "question": "Which of the following is NOT an advantage of Hadoop?",
        "options": [
            "Fault tolerance",
            "Scalability",
            "Structured data processing only",
            "Cost-effectiveness"
        ],
        "answer": "Structured data processing only"
    },
    {
        "question": "Which component manages and tracks all DataNodes in an HDFS cluster?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "NameNode",
            "YARN"
        ],
        "answer": "NameNode"
    },
    {
        "question": "Which version of Hadoop introduced YARN for resource management?",
        "options": [
            "Hadoop 1.x",
            "Hadoop 2.x",
            "Hadoop 3.x",
            "Hadoop 4.x"
        ],
        "answer": "Hadoop 2.x"
    },
    {
        "question": "What is the primary function of TaskTracker in Hadoop 1.x?",
        "options": [
            "Monitor and execute MapReduce tasks",
            "Store metadata for HDFS",
            "Manage job scheduling",
            "Transfer data from HDFS to local file systems"
        ],
        "answer": "Monitor and execute MapReduce tasks"
    },
    {
        "question": "Which of the following best describes Hadoop Federation?",
        "options": [
            "Multiple NameNodes in a cluster",
            "A technique for managing Hadoop logs",
            "A network security model in Hadoop",
            "A compression technique for HDFS files"
        ],
        "answer": "Multiple NameNodes in a cluster"
    },
    {
        "question": "What happens if the NameNode in HDFS fails?",
        "options": [
            "The cluster continues to work normally",
            "All HDFS operations stop",
            "A new NameNode is automatically created",
            "Only read operations are allowed"
        ],
        "answer": "All HDFS operations stop"
    },
    {
        "question": "Which component in Hadoop is used to integrate with Apache Spark?",
        "options": [
            "HDFS",
            "YARN",
            "Flume",
            "Kafka"
        ],
        "answer": "YARN"
    },
    {
        "question": "Which component in the Hadoop ecosystem is used for querying structured data?",
        "options": [
            "Hive",
            "Pig",
            "HBase",
            "Sqoop"
        ],
        "answer": "Hive"
    },
    {
        "question": "What is the default replication factor in HDFS?",
        "options": [
            "1",
            "2",
            "3",
            "4"
        ],
        "answer": "3"
    },
    {
        "question": "Which process moves data between Hadoop and relational databases?",
        "options": [
            "Flume",
            "Kafka",
            "Sqoop",
            "Oozie"
        ],
        "answer": "Sqoop"
    },
    {
        "question": "Which Hadoop component provides a NoSQL database service?",
        "options": [
            "HBase",
            "Hive",
            "Pig",
            "Mahout"
        ],
        "answer": "HBase"
    },
    {
        "question": "Which of the following is used for workflow scheduling in Hadoop?",
        "options": [
            "Oozie",
            "Zookeeper",
            "Flume",
            "Kafka"
        ],
        "answer": "Oozie"
    },
    {
        "question": "What does HDFS stand for?",
        "options": [
            "Hadoop Distributed File Storage",
            "Hadoop Data File System",
            "Hadoop Distributed File System",
            "Highly Distributed File Storage"
        ],
        "answer": "Hadoop Distributed File System"
    },
    {
        "question": "Which Hadoop component helps in real-time event processing?",
        "options": [
            "Flink",
            "Hive",
            "Pig",
            "Sqoop"
        ],
        "answer": "Flink"
    },
    {
        "question": "Which daemon process runs on the master node in Hadoop?",
        "options": [
            "DataNode",
            "NodeManager",
            "NameNode",
            "TaskTracker"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What does YARN stand for in Hadoop?",
        "options": [
            "Yet Another Resource Negotiator",
            "Your Advanced Resource Node",
            "Yellow Analytics Resource Network",
            "YARN Aggregated Resource Network"
        ],
        "answer": "Yet Another Resource Negotiator"
    },
    {
        "question": "Which of the following is an advantage of using Hadoop?",
        "options": [
            "Supports structured and unstructured data",
            "Only works with SQL databases",
            "Runs only on Windows",
            "Limited scalability"
        ],
        "answer": "Supports structured and unstructured data"
    },
    {
        "question": "Which Hadoop component is responsible for resource allocation and job scheduling?",
        "options": [
            "YARN",
            "HDFS",
            "Hive",
            "Sqoop"
        ],
        "answer": "YARN"
    },
    {
        "question": "What type of data can be processed using Hadoop?",
        "options": [
            "Structured",
            "Unstructured",
            "Semi-structured",
            "All of the above"
        ],
        "answer": "All of the above"
    },
    {
        "question": "What is the purpose of the Secondary NameNode in Hadoop?",
        "options": [
            "Stores backup of HDFS metadata",
            "Replaces the NameNode on failure",
            "Stores user data",
            "Acts as a DataNode"
        ],
        "answer": "Stores backup of HDFS metadata"
    },
    {
        "question": "Which of the following is NOT part of the Hadoop ecosystem?",
        "options": [
            "Spark",
            "Flink",
            "MySQL",
            "Kafka"
        ],
        "answer": "MySQL"
    },
    {
        "question": "Which component in Hadoop is responsible for metadata storage?",
        "options": [
            "DataNode",
            "NameNode",
            "JobTracker",
            "YARN"
        ],
        "answer": "NameNode"
    },
    {
        "question": "Which tool is used for interactive SQL queries in Hadoop?",
        "options": [
            "Pig",
            "HBase",
            "Hive",
            "Flume"
        ],
        "answer": "Hive"
    },
    {
        "question": "In Hadoop, what is the term for dividing a large file into smaller chunks?",
        "options": [
            "Partitioning",
            "Sharding",
            "Block Splitting",
            "Replication"
        ],
        "answer": "Block Splitting"
    },
    {
        "question": "Which protocol does HDFS use for communication between nodes?",
        "options": [
            "HTTP",
            "RPC",
            "FTP",
            "TCP"
        ],
        "answer": "RPC"
    },
    {
        "question": "What is the main purpose of MapReduce in Hadoop?",
        "options": [
            "Data storage",
            "Data processing",
            "Data visualization",
            "Data retrieval"
        ],
        "answer": "Data processing"
    },
    {
        "question": "What does the Hadoop NameNode store?",
        "options": [
            "Raw data",
            "Metadata",
            "User files",
            "Backup files"
        ],
        "answer": "Metadata"
    },
    {
        "question": "Which component helps coordinate distributed applications in Hadoop?",
        "options": [
            "Flume",
            "Zookeeper",
            "Kafka",
            "Hive"
        ],
        "answer": "Zookeeper"
    },
    {
        "question": "Which of the following supports low-latency random read/write operations?",
        "options": [
            "HDFS",
            "HBase",
            "Pig",
            "Hive"
        ],
        "answer": "HBase"
    },
    {
        "question": "What happens when a DataNode in Hadoop fails?",
        "options": [
            "Data is lost",
            "NameNode re-replicates the data",
            "Entire cluster shuts down",
            "New DataNode is created automatically"
        ],
        "answer": "NameNode re-replicates the data"
    },
    {
        "question": "Which of the following is NOT a Hadoop-compatible file format?",
        "options": [
            "Parquet",
            "Avro",
            "JSON",
            "Excel"
        ],
        "answer": "Excel"
    },
    {
        "question": "Which component in Hadoop allows running parallel computations?",
        "options": [
            "MapReduce",
            "HDFS",
            "Zookeeper",
            "Oozie"
        ],
        "answer": "MapReduce"
    },
    {
        "question": "Which of the following supports OLAP queries in Hadoop?",
        "options": [
            "Hive",
            "Pig",
            "Flume",
            "Kafka"
        ],
        "answer": "Hive"
    },
    {
        "question": "What type of database is HBase?",
        "options": [
            "Relational",
            "Key-Value Store",
            "Graph",
            "Document"
        ],
        "answer": "Key-Value Store"
    },
    {
        "question": "Which programming model does Hadoop use for distributed computing?",
        "options": [
            "MapReduce",
            "SQL",
            "NoSQL",
            "ETL"
        ],
        "answer": "MapReduce"
    },
    {
        "question": "Which of the following allows real-time log ingestion in Hadoop?",
        "options": [
            "Flume",
            "Sqoop",
            "Hive",
            "HBase"
        ],
        "answer": "Flume"
    },
    {
        "question": "Which tool is used for data serialization in Hadoop?",
        "options": [
            "Avro",
            "Parquet",
            "CSV",
            "XML"
        ],
        "answer": "Avro"
    },
    {
        "question": "What is the function of the checkpointing process in Hadoop?",
        "options": [
            "Reduces NameNode metadata size",
            "Replicates data to backup nodes",
            "Automatically recovers failed jobs",
            "Provides high availability"
        ],
        "answer": "Reduces NameNode metadata size"
    },
    {
        "question": "Which component is responsible for monitoring and managing Hadoop clusters?",
        "options": [
            "Ambari",
            "Zookeeper",
            "Flume",
            "Kafka"
        ],
        "answer": "Ambari"
    },
    {
        "question": "What is the primary function of HDFS in the Hadoop ecosystem?",
        "options": [
            "To process data in parallel",
            "To store and manage large files efficiently",
            "To perform real-time analytics",
            "To provide relational database capabilities"
        ],
        "answer": "To store and manage large files efficiently"
    },
    {
        "question": "Which component of HDFS stores metadata about the file system?",
        "options": [
            "DataNode",
            "Secondary NameNode",
            "NameNode",
            "YARN"
        ],
        "answer": "NameNode"
    },
    {
        "question": "In HDFS, how is data stored across the cluster?",
        "options": [
            "As files",
            "As tables",
            "As blocks",
            "As JSON objects"
        ],
        "answer": "As blocks"
    },
    {
        "question": "What is the default block size in HDFS for Hadoop 2.x and later?",
        "options": [
            "64MB",
            "128MB",
            "256MB",
            "512MB"
        ],
        "answer": "128MB"
    },
    {
        "question": "What happens if a DataNode fails in HDFS?",
        "options": [
            "The cluster stops working",
            "The NameNode re-replicates the missing data",
            "Data is lost",
            "The failed DataNode is automatically restarted"
        ],
        "answer": "The NameNode re-replicates the missing data"
    },
    {
        "question": "Which command is used to list all files in an HDFS directory?",
        "options": [
            "hdfs dfs -ls",
            "hdfs dfs -rm",
            "hdfs dfs -put",
            "hdfs dfs -get"
        ],
        "answer": "hdfs dfs -ls"
    },
    {
        "question": "Which of the following is NOT a feature of HDFS?",
        "options": [
            "Fault tolerance",
            "Data replication",
            "Support for low-latency reads",
            "Scalability"
        ],
        "answer": "Support for low-latency reads"
    },
    {
        "question": "What is the role of the Secondary NameNode in HDFS?",
        "options": [
            "It replaces the NameNode when it fails",
            "It stores a backup of the NameNode’s metadata",
            "It stores data blocks",
            "It processes MapReduce jobs"
        ],
        "answer": "It stores a backup of the NameNode’s metadata"
    },
    {
        "question": "What does the HDFS `hdfs dfs -put` command do?",
        "options": [
            "Deletes a file from HDFS",
            "Retrieves a file from HDFS",
            "Uploads a file to HDFS",
            "Lists files in an HDFS directory"
        ],
        "answer": "Uploads a file to HDFS"
    },
    {
        "question": "How does HDFS ensure high availability?",
        "options": [
            "By using a single NameNode",
            "By replicating data across multiple DataNodes",
            "By compressing data",
            "By using an SQL database"
        ],
        "answer": "By replicating data across multiple DataNodes"
    },
    {
        "question": "Which daemon is responsible for storing actual data in HDFS?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "JobTracker"
        ],
        "answer": "DataNode"
    },
    {
        "question": "What is the main disadvantage of the traditional HDFS architecture?",
        "options": [
            "Lack of data replication",
            "Single point of failure in NameNode",
            "Limited scalability",
            "Requires a Windows OS"
        ],
        "answer": "Single point of failure in NameNode"
    },
    {
        "question": "Which of the following components is responsible for storing HDFS metadata on disk?",
        "options": [
            "NameNode",
            "DataNode",
            "Checkpoint Node",
            "JobTracker"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What does an HDFS block store?",
        "options": [
            "User metadata",
            "File system metadata",
            "Actual file data",
            "Job execution details"
        ],
        "answer": "Actual file data"
    },
    {
        "question": "Which of the following commands is used to delete a file in HDFS?",
        "options": [
            "hdfs dfs -rm",
            "hdfs dfs -ls",
            "hdfs dfs -copyToLocal",
            "hdfs dfs -mkdir"
        ],
        "answer": "hdfs dfs -rm"
    },
    {
        "question": "Which component in Hadoop handles file system namespace and manages access?",
        "options": [
            "ResourceManager",
            "NameNode",
            "DataNode",
            "MapReduce"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What is the function of the fsimage file in HDFS?",
        "options": [
            "Stores the entire namespace metadata",
            "Contains actual file data",
            "Records job execution history",
            "Manages MapReduce job scheduling"
        ],
        "answer": "Stores the entire namespace metadata"
    },
    {
        "question": "Which feature of HDFS allows adding more machines to scale horizontally?",
        "options": [
            "Data Replication",
            "Block Caching",
            "Fault Tolerance",
            "Scalability"
        ],
        "answer": "Scalability"
    },
    {
        "question": "What happens when an HDFS block is corrupted?",
        "options": [
            "The file is deleted",
            "Hadoop stops working",
            "A replica is used to recover the block",
            "The entire DataNode is shut down"
        ],
        "answer": "A replica is used to recover the block"
    },
    {
        "question": "Which factor determines the number of copies of a file in HDFS?",
        "options": [
            "Block size",
            "Replication factor",
            "File size",
            "Cluster size"
        ],
        "answer": "Replication factor"
    },
    {
        "question": "What is the role of the Edit Log in HDFS?",
        "options": [
            "Stores metadata changes",
            "Keeps track of HDFS block replication",
            "Holds data blocks",
            "Manages HDFS client connections"
        ],
        "answer": "Stores metadata changes"
    },
    {
        "question": "Which of the following is a key advantage of HDFS?",
        "options": [
            "Supports low-latency access",
            "Works well with small files",
            "Handles large-scale data efficiently",
            "Requires a relational database"
        ],
        "answer": "Handles large-scale data efficiently"
    },
    {
        "question": "Which of the following is NOT a valid HDFS command?",
        "options": [
            "hdfs dfs -get",
            "hdfs dfs -put",
            "hdfs dfs -run",
            "hdfs dfs -copyFromLocal"
        ],
        "answer": "hdfs dfs -run"
    },
    {
        "question": "What is the minimum replication factor in HDFS?",
        "options": [
            "0",
            "1",
            "2",
            "3"
        ],
        "answer": "1"
    },
    {
        "question": "Which of the following is NOT a valid state for an HDFS block?",
        "options": [
            "Corrupt",
            "Under-replicated",
            "Over-replicated",
            "Compressed"
        ],
        "answer": "Compressed"
    },
    {
        "question": "Which of the following file systems can be used as an alternative to HDFS in Hadoop?",
        "options": [
            "NTFS",
            "EXT4",
            "Amazon S3",
            "FAT32"
        ],
        "answer": "Amazon S3"
    },
    {
        "question": "What type of architecture does HDFS follow?",
        "options": [
            "Master-Slave",
            "Peer-to-Peer",
            "Client-Server",
            "Decentralized"
        ],
        "answer": "Master-Slave"
    },
    {
        "question": "Which of the following is responsible for mapping file names to blocks in HDFS?",
        "options": [
            "DataNode",
            "NameNode",
            "Secondary NameNode",
            "TaskTracker"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What happens when a new file is written to HDFS?",
        "options": [
            "It is stored in a single DataNode",
            "It is split into blocks and distributed across multiple DataNodes",
            "It is compressed and stored in NameNode",
            "It is processed using MapReduce before storage"
        ],
        "answer": "It is split into blocks and distributed across multiple DataNodes"
    },
    {
        "question": "How does HDFS handle hardware failures?",
        "options": [
            "By using RAID storage",
            "By automatically replicating data across multiple DataNodes",
            "By compressing files",
            "By shutting down the failed node"
        ],
        "answer": "By automatically replicating data across multiple DataNodes"
    },
    {
        "question": "Which of the following best describes an HDFS block?",
        "options": [
            "A fixed-size chunk of data",
            "A directory containing files",
            "A temporary storage unit",
            "A file system index"
        ],
        "answer": "A fixed-size chunk of data"
    },
    {
        "question": "What is the default replication factor in HDFS?",
        "options": [
            "2",
            "3",
            "4",
            "5"
        ],
        "answer": "3"
    },
    {
        "question": "Which daemon in HDFS communicates with the NameNode to report storage information?",
        "options": [
            "ResourceManager",
            "TaskTracker",
            "DataNode",
            "JobTracker"
        ],
        "answer": "DataNode"
    },
    {
        "question": "Which file system operation is NOT supported in HDFS?",
        "options": [
            "Appending data to a file",
            "Renaming a file",
            "Updating a part of a file",
            "Deleting a file"
        ],
        "answer": "Updating a part of a file"
    },
    {
        "question": "What is the primary role of the Checkpoint Node in HDFS?",
        "options": [
            "Periodically merges the fsimage and edit log to prevent excessive growth",
            "Stores the data blocks",
            "Manages user access permissions",
            "Monitors cluster health"
        ],
        "answer": "Periodically merges the fsimage and edit log to prevent excessive growth"
    },
    {
        "question": "Which of the following is NOT a component of HDFS?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "Secondary NameNode"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "Which of the following commands is used to copy a file from HDFS to the local filesystem?",
        "options": [
            "hdfs dfs -put",
            "hdfs dfs -copyToLocal",
            "hdfs dfs -ls",
            "hdfs dfs -moveFromLocal"
        ],
        "answer": "hdfs dfs -copyToLocal"
    },
    {
        "question": "How does HDFS handle a corrupt block?",
        "options": [
            "Deletes the entire file",
            "Retrieves a copy from another DataNode",
            "Marks the file as unreadable",
            "Stops the cluster"
        ],
        "answer": "Retrieves a copy from another DataNode"
    },
    {
        "question": "Which type of files are best suited for HDFS storage?",
        "options": [
            "Small files of less than 1MB",
            "Large files greater than 100MB",
            "Compressed archives",
            "Binary executable files"
        ],
        "answer": "Large files greater than 100MB"
    },
    {
        "question": "Which command is used to create a directory in HDFS?",
        "options": [
            "hdfs dfs -mkdir",
            "hdfs dfs -rm",
            "hdfs dfs -copyFromLocal",
            "hdfs dfs -ls"
        ],
        "answer": "hdfs dfs -mkdir"
    },
    {
        "question": "What happens if the NameNode fails in an HDFS cluster without a backup?",
        "options": [
            "DataNodes take over its role",
            "The entire cluster becomes inaccessible",
            "Data gets lost",
            "Replication factor increases automatically"
        ],
        "answer": "The entire cluster becomes inaccessible"
    },
    {
        "question": "What is the purpose of HDFS Federation?",
        "options": [
            "To allow multiple NameNodes to manage different parts of the namespace",
            "To provide high availability",
            "To store files in memory",
            "To replicate data across multiple clusters"
        ],
        "answer": "To allow multiple NameNodes to manage different parts of the namespace"
    },
    {
        "question": "Which of the following is NOT an advantage of HDFS?",
        "options": [
            "Fault tolerance",
            "Scalability",
            "Real-time data processing",
            "Distributed storage"
        ],
        "answer": "Real-time data processing"
    },
    {
        "question": "Which component periodically checks the health of DataNodes in an HDFS cluster?",
        "options": [
            "NameNode",
            "Secondary NameNode",
            "Checkpoint Node",
            "HDFS Gateway"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What is the purpose of the 'Safe Mode' in HDFS?",
        "options": [
            "Prevents new writes while performing system recovery",
            "Locks user access",
            "Increases data replication",
            "Speeds up data processing"
        ],
        "answer": "Prevents new writes while performing system recovery"
    },
    {
        "question": "How does HDFS achieve high throughput?",
        "options": [
            "By using a high-speed SSD storage",
            "By parallelizing data access across multiple nodes",
            "By keeping all data in RAM",
            "By using a single NameNode"
        ],
        "answer": "By parallelizing data access across multiple nodes"
    },
    {
        "question": "Which process ensures that an HDFS file is not corrupted during replication?",
        "options": [
            "DataNode Heartbeats",
            "Checksum Verification",
            "YARN Scheduler",
            "MapReduce Jobs"
        ],
        "answer": "Checksum Verification"
    },
    {
        "question": "Which of the following best describes HDFS snapshots?",
        "options": [
            "A copy of data stored in another cluster",
            "A read-only backup of the file system at a point in time",
            "A compressed archive of HDFS metadata",
            "A real-time file system backup"
        ],
        "answer": "A read-only backup of the file system at a point in time"
    },
    {
        "question": "Which command is used to remove an empty directory in HDFS?",
        "options": [
            "hdfs dfs -rm",
            "hdfs dfs -rmdir",
            "hdfs dfs -put",
            "hdfs dfs -get"
        ],
        "answer": "hdfs dfs -rmdir"
    },
    {
        "question": "What is the primary responsibility of the NameNode in HDFS?",
        "options": [
            "Store actual data blocks",
            "Manage metadata and namespace",
            "Run MapReduce jobs",
            "Manage YARN applications"
        ],
        "answer": "Manage metadata and namespace"
    },
    {
        "question": "Which daemon in Hadoop is responsible for storing actual file data in HDFS?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "Secondary NameNode"
        ],
        "answer": "DataNode"
    },
    {
        "question": "What is the role of the Secondary NameNode?",
        "options": [
            "Acts as a backup NameNode",
            "Stores actual data blocks",
            "Merges fsimage and edit logs",
            "Processes MapReduce jobs"
        ],
        "answer": "Merges fsimage and edit logs"
    },
    {
        "question": "Which of the following operations is NOT performed by the NameNode?",
        "options": [
            "Managing metadata",
            "Storing actual data blocks",
            "Tracking block locations",
            "Handling client file operations"
        ],
        "answer": "Storing actual data blocks"
    },
    {
        "question": "Which command is used to check the status of HDFS nodes?",
        "options": [
            "hdfs dfsadmin -report",
            "hdfs dfs -ls",
            "hdfs dfs -du",
            "hadoop fs -put"
        ],
        "answer": "hdfs dfsadmin -report"
    },
    {
        "question": "How does HDFS store a file across multiple nodes?",
        "options": [
            "By splitting the file into blocks and replicating them",
            "By compressing the file and storing it in one node",
            "By distributing equal parts of a file across all nodes",
            "By storing entire files in multiple locations"
        ],
        "answer": "By splitting the file into blocks and replicating them"
    },
    {
        "question": "Which Hadoop command is used to move files into HDFS?",
        "options": [
            "hdfs dfs -put",
            "hdfs dfs -get",
            "hdfs dfs -copyToLocal",
            "hdfs dfs -rm"
        ],
        "answer": "hdfs dfs -put"
    },
    {
        "question": "Which of the following commands is used to list files in HDFS?",
        "options": [
            "hdfs dfs -ls",
            "hdfs dfs -rm",
            "hdfs dfs -get",
            "hdfs dfs -copyFromLocal"
        ],
        "answer": "hdfs dfs -ls"
    },
    {
        "question": "What does YARN stand for in Hadoop?",
        "options": [
            "Yet Another Resource Negotiator",
            "Yellow Advanced Resource Network",
            "Yahoo's Advanced Resource Node",
            "Yield Algorithm for Redundant Nodes"
        ],
        "answer": "Yet Another Resource Negotiator"
    },
    {
        "question": "Which component of YARN is responsible for tracking resource usage across nodes?",
        "options": [
            "NodeManager",
            "ResourceManager",
            "ApplicationMaster",
            "NameNode"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "Which YARN daemon runs on worker nodes?",
        "options": [
            "ResourceManager",
            "NameNode",
            "NodeManager",
            "DataNode"
        ],
        "answer": "NodeManager"
    },
    {
        "question": "What happens when a DataNode fails in Hadoop?",
        "options": [
            "The cluster stops working",
            "The NameNode removes it from the cluster and replicates its data",
            "All jobs fail",
            "YARN restarts the node automatically"
        ],
        "answer": "The NameNode removes it from the cluster and replicates its data"
    },
    {
        "question": "Which file system command is used to remove a file in HDFS?",
        "options": [
            "hdfs dfs -rm",
            "hdfs dfs -rmdir",
            "hdfs dfs -ls",
            "hdfs dfs -get"
        ],
        "answer": "hdfs dfs -rm"
    },
    {
        "question": "Which command is used to copy a file from local storage to HDFS?",
        "options": [
            "hdfs dfs -copyFromLocal",
            "hdfs dfs -get",
            "hdfs dfs -rm",
            "hdfs dfs -put"
        ],
        "answer": "hdfs dfs -copyFromLocal"
    },
    {
        "question": "Which process in YARN is responsible for launching and monitoring application containers?",
        "options": [
            "NodeManager",
            "ResourceManager",
            "ApplicationMaster",
            "DataNode"
        ],
        "answer": "NodeManager"
    },
    {
        "question": "Which of the following is NOT a function of the Secondary NameNode?",
        "options": [
            "Maintaining an updated copy of fsimage",
            "Assisting in NameNode recovery",
            "Processing metadata transactions",
            "Replacing the NameNode during failure"
        ],
        "answer": "Replacing the NameNode during failure"
    },
    {
        "question": "Which YARN component is responsible for job scheduling and cluster resource management?",
        "options": [
            "ResourceManager",
            "NodeManager",
            "TaskTracker",
            "ApplicationMaster"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "Which of the following best describes an ApplicationMaster in YARN?",
        "options": [
            "Manages a specific application’s lifecycle",
            "Allocates memory across all jobs",
            "Tracks block locations",
            "Performs health monitoring"
        ],
        "answer": "Manages a specific application’s lifecycle"
    },
    {
        "question": "What is the primary purpose of YARN in Hadoop?",
        "options": [
            "To provide resource management and job scheduling",
            "To store large datasets",
            "To replicate data across nodes",
            "To replace MapReduce"
        ],
        "answer": "To provide resource management and job scheduling"
    },
    {
        "question": "Which command is used to create a new directory in HDFS?",
        "options": [
            "hdfs dfs -mkdir",
            "hdfs dfs -rm",
            "hdfs dfs -ls",
            "hdfs dfs -du"
        ],
        "answer": "hdfs dfs -mkdir"
    },
    {
        "question": "Which Hadoop command is used to change file permissions in HDFS?",
        "options": [
            "hdfs dfs -chmod",
            "hdfs dfs -chown",
            "hdfs dfs -ls",
            "hdfs dfs -cp"
        ],
        "answer": "hdfs dfs -chmod"
    },
    {
        "question": "Which of the following best describes a Container in YARN?",
        "options": [
            "A process that executes a task with allocated resources",
            "A virtualized instance of Hadoop",
            "A replacement for MapReduce",
            "A metadata storage unit"
        ],
        "answer": "A process that executes a task with allocated resources"
    },
    {
        "question": "What is the purpose of the 'shuffle and sort' phase in MapReduce?",
        "options": [
            "To distribute input data evenly",
            "To group and order intermediate key-value pairs",
            "To store data in HDFS",
            "To split files into blocks"
        ],
        "answer": "To group and order intermediate key-value pairs"
    },
    {
        "question": "Which of the following is NOT a valid role of a DataNode?",
        "options": [
            "Storing file blocks",
            "Replicating blocks",
            "Executing MapReduce jobs",
            "Sending heartbeat signals to the NameNode"
        ],
        "answer": "Executing MapReduce jobs"
    },
    {
        "question": "What happens when the NameNode fails in an HDFS cluster?",
        "options": [
            "The cluster continues to function normally",
            "All data is lost permanently",
            "HDFS enters a read-only mode until recovery",
            "A standby or Secondary NameNode can take over"
        ],
        "answer": "HDFS enters a read-only mode until recovery"
    },
    {
        "question": "Which process is responsible for writing metadata changes to an edit log in HDFS?",
        "options": [
            "DataNode",
            "NameNode",
            "Secondary NameNode",
            "NodeManager"
        ],
        "answer": "NameNode"
    },
    {
        "question": "Which file in HDFS stores the most recent snapshot of the file system namespace?",
        "options": [
            "Edit log",
            "Fsimage",
            "Block report",
            "Hadoop log"
        ],
        "answer": "Fsimage"
    },
    {
        "question": "How does a DataNode report block information to the NameNode?",
        "options": [
            "By sending heartbeats",
            "By storing metadata locally",
            "By executing MapReduce tasks",
            "By running YARN jobs"
        ],
        "answer": "By sending heartbeats"
    },
    {
        "question": "What is the default block size in HDFS?",
        "options": [
            "64 MB",
            "128 MB",
            "256 MB",
            "512 MB"
        ],
        "answer": "128 MB"
    },
    {
        "question": "Which command is used to check HDFS file permissions?",
        "options": [
            "hdfs dfs -ls",
            "hdfs dfs -chmod",
            "hdfs dfs -stat",
            "hdfs dfs -du"
        ],
        "answer": "hdfs dfs -ls"
    },
    {
        "question": "Which command retrieves a file from HDFS to the local file system?",
        "options": [
            "hdfs dfs -get",
            "hdfs dfs -put",
            "hdfs dfs -copyToLocal",
            "hdfs dfs -mv"
        ],
        "answer": "hdfs dfs -get"
    },
    {
        "question": "Which tool is used to monitor Hadoop cluster performance?",
        "options": [
            "Ganglia",
            "Prometheus",
            "Grafana",
            "YARN"
        ],
        "answer": "Ganglia"
    },
    {
        "question": "What is the function of a JobTracker in older versions of Hadoop?",
        "options": [
            "Manages metadata",
            "Schedules and monitors jobs",
            "Stores file blocks",
            "Replicates data"
        ],
        "answer": "Schedules and monitors jobs"
    },
    {
        "question": "Which process in YARN negotiates resources for an application?",
        "options": [
            "ResourceManager",
            "NodeManager",
            "ApplicationMaster",
            "JobTracker"
        ],
        "answer": "ApplicationMaster"
    },
    {
        "question": "How does HDFS ensure fault tolerance?",
        "options": [
            "By using RAID storage",
            "By maintaining replicas of data blocks",
            "By storing data in relational databases",
            "By compressing all files"
        ],
        "answer": "By maintaining replicas of data blocks"
    },
    {
        "question": "Which protocol does HDFS use for communication between nodes?",
        "options": [
            "TCP/IP",
            "UDP",
            "HTTP",
            "FTP"
        ],
        "answer": "TCP/IP"
    },
    {
        "question": "What is the role of an ApplicationMaster in YARN?",
        "options": [
            "Manages and monitors a specific application",
            "Allocates storage space in HDFS",
            "Performs file system repairs",
            "Handles metadata synchronization"
        ],
        "answer": "Manages and monitors a specific application"
    },
    {
        "question": "Which file contains the list of DataNodes that should be excluded from the cluster?",
        "options": [
            "exclude",
            "datanode.blocklist",
            "datanodes.txt",
            "hdfs.exclude"
        ],
        "answer": "exclude"
    },
    {
        "question": "Which process is responsible for managing the job queue in YARN?",
        "options": [
            "ResourceManager",
            "NodeManager",
            "TaskTracker",
            "Secondary NameNode"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "Which YARN scheduler allows dynamic resource allocation?",
        "options": [
            "Capacity Scheduler",
            "FIFO Scheduler",
            "Fair Scheduler",
            "Round Robin Scheduler"
        ],
        "answer": "Fair Scheduler"
    },
    {
        "question": "What is the main benefit of using YARN?",
        "options": [
            "It eliminates the need for HDFS",
            "It separates resource management from job execution",
            "It replaces the need for NameNode",
            "It speeds up network communication"
        ],
        "answer": "It separates resource management from job execution"
    },
    {
        "question": "Which command in Hadoop checks disk usage for files in HDFS?",
        "options": [
            "hdfs dfs -du",
            "hdfs dfs -ls",
            "hdfs dfs -df",
            "hdfs dfs -mv"
        ],
        "answer": "hdfs dfs -du"
    },
    {
        "question": "What is the purpose of the HDFS safemode?",
        "options": [
            "To prevent writes while the system is starting",
            "To delete all data in HDFS",
            "To run MapReduce jobs",
            "To restart DataNodes"
        ],
        "answer": "To prevent writes while the system is starting"
    },
    {
        "question": "Which YARN mode runs applications on a single node for testing?",
        "options": [
            "Standalone mode",
            "Cluster mode",
            "Pseudo-distributed mode",
            "Distributed mode"
        ],
        "answer": "Standalone mode"
    },
    {
        "question": "Which file in Hadoop stores cluster configuration details?",
        "options": [
            "core-site.xml",
            "hdfs-site.xml",
            "yarn-site.xml",
            "mapred-site.xml"
        ],
        "answer": "core-site.xml"
    },
    {
        "question": "What happens when the Secondary NameNode fails?",
        "options": [
            "The cluster continues running normally",
            "The NameNode stops functioning",
            "All DataNodes shut down",
            "The metadata is lost"
        ],
        "answer": "The cluster continues running normally"
    },
    {
        "question": "What type of metadata does the NameNode store?",
        "options": [
            "Block locations",
            "User data",
            "Application logs",
            "Node IP addresses"
        ],
        "answer": "Block locations"
    },
    {
        "question": "Which component is responsible for allocating containers in YARN?",
        "options": [
            "ResourceManager",
            "ApplicationMaster",
            "NodeManager",
            "TaskTracker"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "Which command displays a list of active nodes in HDFS?",
        "options": [
            "hdfs dfsadmin -report",
            "hdfs dfs -ls",
            "hdfs dfs -stat",
            "hdfs dfs -count"
        ],
        "answer": "hdfs dfsadmin -report"
    },
    {
        "question": "Which YARN mode allows full distributed processing across multiple nodes?",
        "options": [
            "Cluster mode",
            "Standalone mode",
            "Pseudo-distributed mode",
            "Local mode"
        ],
        "answer": "Cluster mode"
    },
    {
        "question": "What is the primary goal of Hadoop on YARN?",
        "options": [
            "To replace HDFS",
            "To improve resource management and job scheduling",
            "To store large-scale structured data",
            "To process small-scale datasets"
        ],
        "answer": "To improve resource management and job scheduling"
    },
    {
        "question": "What is the primary function of the Map phase in MapReduce?",
        "options": [
            "To filter and sort input data",
            "To aggregate data",
            "To store data in HDFS",
            "To schedule jobs"
        ],
        "answer": "To filter and sort input data"
    },
    {
        "question": "Which component in MapReduce is responsible for splitting input data into smaller chunks?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "InputFormat",
            "Reducer"
        ],
        "answer": "InputFormat"
    },
    {
        "question": "Which data structure is used for key-value pair output from the Map function?",
        "options": [
            "List",
            "Tuple",
            "Dictionary",
            "HashMap"
        ],
        "answer": "Tuple"
    },
    {
        "question": "Which phase comes after the Map phase in a MapReduce job?",
        "options": [
            "Reduce",
            "Shuffle",
            "Partitioning",
            "Combiner"
        ],
        "answer": "Shuffle"
    },
    {
        "question": "What is the primary function of the Reduce phase in MapReduce?",
        "options": [
            "To distribute input data",
            "To aggregate and summarize data",
            "To filter out invalid data",
            "To store data in HDFS"
        ],
        "answer": "To aggregate and summarize data"
    },
    {
        "question": "Which step in MapReduce is responsible for grouping intermediate key-value pairs?",
        "options": [
            "Partitioning",
            "Shuffling",
            "Combining",
            "Splitting"
        ],
        "answer": "Shuffling"
    },
    {
        "question": "Which component in MapReduce is responsible for distributing tasks to nodes in a cluster?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "ResourceManager",
            "NodeManager"
        ],
        "answer": "JobTracker"
    },
    {
        "question": "What is the role of a Combiner in MapReduce?",
        "options": [
            "It performs a local reduce operation before shuffling",
            "It merges output files",
            "It schedules jobs",
            "It stores job metadata"
        ],
        "answer": "It performs a local reduce operation before shuffling"
    },
    {
        "question": "Which command is used to submit a MapReduce job?",
        "options": [
            "hadoop jar",
            "hdfs dfs -put",
            "yarn jar",
            "mapreduce-submit"
        ],
        "answer": "hadoop jar"
    },
    {
        "question": "Which file format is commonly used for input in a MapReduce job?",
        "options": [
            "CSV",
            "JSON",
            "SequenceFile",
            "All of the above"
        ],
        "answer": "All of the above"
    },
    {
        "question": "What is the role of a Partitioner in MapReduce?",
        "options": [
            "It divides input data among Mappers",
            "It determines how key-value pairs are distributed to Reducers",
            "It merges intermediate results",
            "It performs final aggregation"
        ],
        "answer": "It determines how key-value pairs are distributed to Reducers"
    },
    {
        "question": "What is the default partitioning function in Hadoop?",
        "options": [
            "HashPartitioner",
            "RangePartitioner",
            "CustomPartitioner",
            "RandomPartitioner"
        ],
        "answer": "HashPartitioner"
    },
    {
        "question": "Which component in Hadoop stores job metadata and task status?",
        "options": [
            "JobTracker",
            "NameNode",
            "DataNode",
            "TaskTracker"
        ],
        "answer": "JobTracker"
    },
    {
        "question": "Which factor determines the number of Mappers in a job?",
        "options": [
            "Number of input splits",
            "Number of Reducers",
            "Available CPU cores",
            "Replication factor"
        ],
        "answer": "Number of input splits"
    },
    {
        "question": "How does Hadoop handle job failures in MapReduce?",
        "options": [
            "By restarting failed tasks",
            "By stopping all jobs",
            "By manually assigning new tasks",
            "By logging the failure but continuing"
        ],
        "answer": "By restarting failed tasks"
    },
    {
        "question": "Which component in MapReduce tracks and manages the execution of tasks?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "NodeManager",
            "ResourceManager"
        ],
        "answer": "TaskTracker"
    },
    {
        "question": "Which scheduling algorithm does Hadoop use by default?",
        "options": [
            "FIFO",
            "Fair Scheduler",
            "Capacity Scheduler",
            "Round Robin"
        ],
        "answer": "FIFO"
    },
    {
        "question": "What is speculative execution in Hadoop?",
        "options": [
            "Running duplicate tasks on different nodes to handle slow nodes",
            "Executing tasks in a random order",
            "Reducing the number of Reducers",
            "Executing tasks only after Reduce phase starts"
        ],
        "answer": "Running duplicate tasks on different nodes to handle slow nodes"
    },
    {
        "question": "Which scheduling algorithm allows fair distribution of resources among multiple users?",
        "options": [
            "Fair Scheduler",
            "FIFO",
            "Round Robin",
            "Capacity Scheduler"
        ],
        "answer": "Fair Scheduler"
    },
    {
        "question": "Which component stores job history in Hadoop?",
        "options": [
            "JobHistory Server",
            "TaskTracker",
            "JobTracker",
            "NameNode"
        ],
        "answer": "JobHistory Server"
    },
    {
        "question": "What happens when a Reducer finishes processing all assigned keys?",
        "options": [
            "It writes output to HDFS",
            "It waits for other tasks to complete",
            "It deletes input data",
            "It restarts execution"
        ],
        "answer": "It writes output to HDFS"
    },
    {
        "question": "What is the default output format of a MapReduce job?",
        "options": [
            "TextOutputFormat",
            "SequenceFileOutputFormat",
            "JSONOutputFormat",
            "AvroOutputFormat"
        ],
        "answer": "TextOutputFormat"
    },
    {
        "question": "Which process in MapReduce groups values by key before sending them to Reducers?",
        "options": [
            "Sorting",
            "Partitioning",
            "Shuffling",
            "Merging"
        ],
        "answer": "Shuffling"
    },
    {
        "question": "Which Java interface should a Mapper class extend?",
        "options": [
            "Mapper",
            "Reducer",
            "JobConf",
            "Partitioner"
        ],
        "answer": "Mapper"
    },
    {
        "question": "Which phase in MapReduce ensures that all values for a key are processed together?",
        "options": [
            "Shuffle and Sort",
            "Partitioning",
            "Combining",
            "Splitting"
        ],
        "answer": "Shuffle and Sort"
    },
    {
        "question": "What happens if a task fails multiple times in Hadoop?",
        "options": [
            "The job is marked as failed",
            "Hadoop retries the task indefinitely",
            "The failed task is ignored",
            "The cluster shuts down"
        ],
        "answer": "The job is marked as failed"
    },
    {
        "question": "What is the purpose of Job Scheduling in MapReduce?",
        "options": [
            "To assign resources efficiently among multiple jobs",
            "To store job output",
            "To merge intermediate results",
            "To compress job logs"
        ],
        "answer": "To assign resources efficiently among multiple jobs"
    },
    {
        "question": "Which phase in MapReduce ensures that intermediate data reaches the correct Reducer?",
        "options": [
            "Partitioning",
            "Combining",
            "Shuffling",
            "Merging"
        ],
        "answer": "Partitioning"
    },
    {
        "question": "Which method in the Mapper class processes each key-value pair?",
        "options": [
            "setup()",
            "map()",
            "reduce()",
            "cleanup()"
        ],
        "answer": "map()"
    },
    {
        "question": "What is the output of the Mapper phase?",
        "options": [
            "Intermediate key-value pairs",
            "Final aggregated results",
            "HDFS blocks",
            "Compressed files"
        ],
        "answer": "Intermediate key-value pairs"
    },
    {
        "question": "Which Hadoop property allows a Reducer to run multiple times for different keys?",
        "options": [
            "mapreduce.reduce.tasks",
            "mapreduce.job.reduces",
            "yarn.nodemanager.resource.memory",
            "dfs.replication"
        ],
        "answer": "mapreduce.job.reduces"
    },
    {
        "question": "What is the default input format for a MapReduce job?",
        "options": [
            "TextInputFormat",
            "SequenceFileInputFormat",
            "KeyValueTextInputFormat",
            "JSONInputFormat"
        ],
        "answer": "TextInputFormat"
    },
    {
        "question": "Which phase occurs before the Reduce phase in a MapReduce job?",
        "options": [
            "Shuffling",
            "Combining",
            "Partitioning",
            "Grouping"
        ],
        "answer": "Shuffling"
    },
    {
        "question": "Which component in Hadoop splits input data into smaller parts for processing?",
        "options": [
            "InputFormat",
            "Mapper",
            "Reducer",
            "Combiner"
        ],
        "answer": "InputFormat"
    },
    {
        "question": "What is the default replication factor in HDFS?",
        "options": [
            "1",
            "2",
            "3",
            "5"
        ],
        "answer": "3"
    },
    {
        "question": "Which step in MapReduce ensures data locality?",
        "options": [
            "Input Split",
            "Partitioning",
            "Combiner",
            "Shuffling"
        ],
        "answer": "Input Split"
    },
    {
        "question": "Which component in YARN is responsible for scheduling MapReduce jobs?",
        "options": [
            "ResourceManager",
            "NodeManager",
            "JobTracker",
            "TaskTracker"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "Which file format in Hadoop provides efficient compression and fast processing?",
        "options": [
            "Parquet",
            "CSV",
            "JSON",
            "XML"
        ],
        "answer": "Parquet"
    },
    {
        "question": "Which method in the Reducer class is executed once before reducing starts?",
        "options": [
            "setup()",
            "reduce()",
            "cleanup()",
            "initialize()"
        ],
        "answer": "setup()"
    },
    {
        "question": "What happens when a node running a Map task fails?",
        "options": [
            "Task is re-executed on another node",
            "Job fails completely",
            "Reducer takes over",
            "Task is ignored"
        ],
        "answer": "Task is re-executed on another node"
    },
    {
        "question": "What is the primary function of the OutputFormat class in MapReduce?",
        "options": [
            "Determines how output is written",
            "Defines input split size",
            "Handles task execution",
            "Schedules jobs"
        ],
        "answer": "Determines how output is written"
    },
    {
        "question": "Which MapReduce component sorts and merges intermediate output before sending it to Reducers?",
        "options": [
            "Partitioner",
            "Combiner",
            "Shuffling",
            "Grouping"
        ],
        "answer": "Shuffling"
    },
    {
        "question": "Which function in the Reducer class aggregates values for a given key?",
        "options": [
            "reduce()",
            "map()",
            "setup()",
            "partition()"
        ],
        "answer": "reduce()"
    },
    {
        "question": "Which class is responsible for defining how input data is read?",
        "options": [
            "InputFormat",
            "OutputFormat",
            "Mapper",
            "Reducer"
        ],
        "answer": "InputFormat"
    },
    {
        "question": "Which configuration parameter controls the number of Reduce tasks?",
        "options": [
            "mapreduce.job.reduces",
            "mapreduce.reduce.tasks",
            "yarn.nodemanager.reducers",
            "mapreduce.num.tasks"
        ],
        "answer": "mapreduce.job.reduces"
    },
    {
        "question": "What is the purpose of the RecordReader class in MapReduce?",
        "options": [
            "Converts input splits into key-value pairs",
            "Assigns tasks to Mappers",
            "Writes output to HDFS",
            "Manages job scheduling"
        ],
        "answer": "Converts input splits into key-value pairs"
    },
    {
        "question": "What is the purpose of speculative execution in Hadoop?",
        "options": [
            "Handles slow-running tasks",
            "Prevents job failures",
            "Improves file replication",
            "Manages job priority"
        ],
        "answer": "Handles slow-running tasks"
    },
    {
        "question": "What happens if the output directory for a MapReduce job already exists?",
        "options": [
            "Job fails",
            "Old data is overwritten",
            "New files are appended",
            "Job runs with errors"
        ],
        "answer": "Job fails"
    },
    {
        "question": "Which method in the Mapper class is called once before processing begins?",
        "options": [
            "setup()",
            "map()",
            "cleanup()",
            "start()"
        ],
        "answer": "setup()"
    },
    {
        "question": "Which component assigns MapReduce tasks to worker nodes?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "NameNode",
            "DataNode"
        ],
        "answer": "JobTracker"
    },
    {
        "question": "What is the primary function of the Combiner?",
        "options": [
            "Performs local aggregation",
            "Assigns jobs to nodes",
            "Manages task scheduling",
            "Sorts intermediate data"
        ],
        "answer": "Performs local aggregation"
    },
    {
        "question": "What is the main advantage of using a Combiner?",
        "options": [
            "Reduces data transfer between Mappers and Reducers",
            "Increases job execution time",
            "Increases replication factor",
            "Sorts final output"
        ],
        "answer": "Reduces data transfer between Mappers and Reducers"
    },
    {
        "question": "Which component in MapReduce ensures that all values for a given key go to the same Reducer?",
        "options": [
            "Partitioner",
            "Shuffling",
            "Combiner",
            "Grouping"
        ],
        "answer": "Partitioner"
    },
    {
        "question": "What determines the number of partitions in a MapReduce job?",
        "options": [
            "Number of Reducers",
            "Number of Mappers",
            "Input Split Size",
            "Replication Factor"
        ],
        "answer": "Number of Reducers"
    },
    {
        "question": "Which of the following is NOT a valid MapReduce output format?",
        "options": [
            "TextOutputFormat",
            "SequenceFileOutputFormat",
            "JSONOutputFormat",
            "AvroOutputFormat"
        ],
        "answer": "JSONOutputFormat"
    },
    {
        "question": "Which scheduler in YARN is designed for multi-tenant clusters?",
        "options": [
            "Fair Scheduler",
            "FIFO Scheduler",
            "Capacity Scheduler",
            "Priority Scheduler"
        ],
        "answer": "Capacity Scheduler"
    },
    {
        "question": "Which Hadoop command lists all running jobs?",
        "options": [
            "hadoop job -list",
            "hadoop fs -ls",
            "hadoop jar -list",
            "hdfs dfs -status"
        ],
        "answer": "hadoop job -list"
    },
    {
        "question": "What is a common cause of job failures in Hadoop MapReduce?",
        "options": [
            "Incorrect output path",
            "Too many reducers",
            "Lack of partitions",
            "Excessive input splits"
        ],
        "answer": "Incorrect output path"
    },
    {
        "question": "Which phase in MapReduce is responsible for transferring intermediate key-value pairs to the reducer?",
        "options": [
            "Shuffle",
            "Sort",
            "Partition",
            "Combiner"
        ],
        "answer": "Shuffle"
    },
    {
        "question": "What does the sorting phase in MapReduce do?",
        "options": [
            "Sorts keys before sending them to reducers",
            "Sorts final output",
            "Sorts input splits",
            "Sorts output files"
        ],
        "answer": "Sorts keys before sending them to reducers"
    },
    {
        "question": "Which phase of MapReduce ensures that records with the same key are grouped together?",
        "options": [
            "Partitioning",
            "Grouping",
            "Sorting",
            "Combining"
        ],
        "answer": "Sorting"
    },
    {
        "question": "In the Word Count problem, what is the key in the intermediate output?",
        "options": [
            "A word",
            "A line of text",
            "A file name",
            "A sentence"
        ],
        "answer": "A word"
    },
    {
        "question": "What is the default sorting order for keys in the shuffle and sort phase?",
        "options": [
            "Ascending",
            "Descending",
            "Random",
            "Unordered"
        ],
        "answer": "Ascending"
    },
    {
        "question": "Which component is responsible for rescheduling failed tasks in MapReduce?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "NodeManager",
            "Reducer"
        ],
        "answer": "JobTracker"
    },
    {
        "question": "Which phase in MapReduce can be optimized using a Combiner?",
        "options": [
            "Shuffling",
            "Sorting",
            "Grouping",
            "Partitioning"
        ],
        "answer": "Shuffling"
    },
    {
        "question": "In the Word Count problem, what does the Reducer do?",
        "options": [
            "Aggregates word counts",
            "Splits words",
            "Reads input files",
            "Sorts words alphabetically"
        ],
        "answer": "Aggregates word counts"
    },
    {
        "question": "How does Hadoop handle a job failure?",
        "options": [
            "Re-executes the failed task",
            "Stops all running jobs",
            "Deletes all output",
            "Starts a new job"
        ],
        "answer": "Re-executes the failed task"
    },
    {
        "question": "Which of the following is NOT a part of the shuffle and sort process?",
        "options": [
            "Merging",
            "Sorting",
            "Partitioning",
            "Combining"
        ],
        "answer": "Partitioning"
    },
    {
        "question": "What is the role of the Partitioner in a MapReduce job?",
        "options": [
            "Assigns keys to reducers",
            "Splits input data",
            "Sorts intermediate output",
            "Merges sorted output"
        ],
        "answer": "Assigns keys to reducers"
    },
    {
        "question": "Which of the following errors can cause a job failure in Hadoop?",
        "options": [
            "Out of memory",
            "Extra reducers",
            "Missing shuffle phase",
            "Invalid replication factor"
        ],
        "answer": "Out of memory"
    },
    {
        "question": "What happens when a Reduce task fails?",
        "options": [
            "It is retried on another node",
            "The job stops",
            "The entire job is restarted",
            "Map tasks are re-executed"
        ],
        "answer": "It is retried on another node"
    },
    {
        "question": "Which method in Hadoop is used for handling task failures?",
        "options": [
            "Speculative Execution",
            "Job Preemption",
            "FIFO Scheduling",
            "Data Replication"
        ],
        "answer": "Speculative Execution"
    },
    {
        "question": "Which of the following is NOT an optimization for the Word Count problem?",
        "options": [
            "Using a Combiner",
            "Increasing input splits",
            "Using multiple reducers",
            "Disabling shuffle phase"
        ],
        "answer": "Disabling shuffle phase"
    },
    {
        "question": "Which function in the shuffle and sort process aggregates values for the same key before they reach the Reducer?",
        "options": [
            "Combiner",
            "Partitioner",
            "Mapper",
            "InputFormat"
        ],
        "answer": "Combiner"
    },
    {
        "question": "Which component of MapReduce is responsible for detecting and handling failed tasks?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "DataNode",
            "ResourceManager"
        ],
        "answer": "JobTracker"
    },
    {
        "question": "What does the Word Count problem demonstrate in MapReduce?",
        "options": [
            "Parallel data processing",
            "Complex data joins",
            "Database indexing",
            "Security in Hadoop"
        ],
        "answer": "Parallel data processing"
    },
    {
        "question": "Which factor influences the performance of shuffle and sort?",
        "options": [
            "Number of reducers",
            "Replication factor",
            "Input file format",
            "Block size"
        ],
        "answer": "Number of reducers"
    },
    {
        "question": "Which MapReduce feature helps reduce data transfer during shuffling?",
        "options": [
            "Compression",
            "In-memory sorting",
            "Increasing partitions",
            "Reducing file splits"
        ],
        "answer": "Compression"
    },
    {
        "question": "What type of data does the Mapper process in Word Count?",
        "options": [
            "Text data",
            "Binary data",
            "Image files",
            "Database records"
        ],
        "answer": "Text data"
    },
    {
        "question": "What is the role of merging in the shuffle and sort phase?",
        "options": [
            "Combines sorted outputs from multiple mappers",
            "Splits input files",
            "Joins database tables",
            "Optimizes memory usage"
        ],
        "answer": "Combines sorted outputs from multiple mappers"
    },
    {
        "question": "Which key-value pair structure is produced in the intermediate output of Word Count?",
        "options": [
            "(word, 1)",
            "(word, count)",
            "(sentence, 1)",
            "(file, word)"
        ],
        "answer": "(word, 1)"
    },
    {
        "question": "Which of the following can lead to performance degradation in shuffle and sort?",
        "options": [
            "High data skew",
            "Multiple reducers",
            "Efficient sorting algorithm",
            "Using a combiner"
        ],
        "answer": "High data skew"
    },
    {
        "question": "Which step occurs last in the shuffle and sort phase?",
        "options": [
            "Sorting",
            "Grouping",
            "Partitioning",
            "Merging"
        ],
        "answer": "Merging"
    },
    {
        "question": "Which output format is commonly used for the Word Count problem?",
        "options": [
            "TextOutputFormat",
            "SequenceFileOutputFormat",
            "ParquetOutputFormat",
            "JSONOutputFormat"
        ],
        "answer": "TextOutputFormat"
    },
    {
        "question": "In the Word Count problem, why is a Combiner useful?",
        "options": [
            "Reduces the volume of data shuffled",
            "Increases job execution time",
            "Skips the reducer phase",
            "Sorts the input data"
        ],
        "answer": "Reduces the volume of data shuffled"
    },
    {
        "question": "What happens when a speculative execution task completes before the original task?",
        "options": [
            "The original task is killed",
            "Both results are used",
            "Job fails",
            "New task is assigned"
        ],
        "answer": "The original task is killed"
    },
    {
        "question": "Which configuration file in Hadoop specifies the number of NameNodes and DataNodes?",
        "options": [
            "core-site.xml",
            "hdfs-site.xml",
            "mapred-site.xml",
            "yarn-site.xml"
        ],
        "answer": "hdfs-site.xml"
    },
    {
        "question": "What is the primary purpose of setting up a Hadoop cluster?",
        "options": [
            "Distributed storage and processing of big data",
            "Hosting web applications",
            "Managing relational databases",
            "Network security"
        ],
        "answer": "Distributed storage and processing of big data"
    },
    {
        "question": "Which mode should Hadoop be configured in for multi-node operation?",
        "options": [
            "Standalone mode",
            "Pseudo-distributed mode",
            "Fully distributed mode",
            "Single-user mode"
        ],
        "answer": "Fully distributed mode"
    },
    {
        "question": "Which of the following is NOT a prerequisite for installing a Hadoop cluster?",
        "options": [
            "Java Development Kit (JDK)",
            "SSH password-less login",
            "Minimum 64GB RAM",
            "Linux-based operating system"
        ],
        "answer": "Minimum 64GB RAM"
    },
    {
        "question": "Which command is used to format the HDFS NameNode before the first use?",
        "options": [
            "hdfs namenode -format",
            "hadoop namenode -init",
            "hadoop format",
            "hdfs format"
        ],
        "answer": "hdfs namenode -format"
    },
    {
        "question": "Which directory in Hadoop contains configuration files?",
        "options": [
            "/etc/hadoop/conf",
            "/usr/local/hadoop/config",
            "/var/hadoop/etc",
            "/hadoop/conf"
        ],
        "answer": "/etc/hadoop/conf"
    },
    {
        "question": "Which component of Hadoop ensures cluster resource management?",
        "options": [
            "HDFS",
            "YARN",
            "MapReduce",
            "Zookeeper"
        ],
        "answer": "YARN"
    },
    {
        "question": "Which file must be modified to specify the replication factor in HDFS?",
        "options": [
            "core-site.xml",
            "hdfs-site.xml",
            "mapred-site.xml",
            "yarn-site.xml"
        ],
        "answer": "hdfs-site.xml"
    },
    {
        "question": "What is the default replication factor in HDFS?",
        "options": [
            "1",
            "2",
            "3",
            "4"
        ],
        "answer": "3"
    },
    {
        "question": "Which of the following is NOT required for a Hadoop cluster?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "MySQL Database"
        ],
        "answer": "MySQL Database"
    },
    {
        "question": "What is the recommended file system for installing Hadoop?",
        "options": [
            "NTFS",
            "Ext4",
            "FAT32",
            "HDFS"
        ],
        "answer": "Ext4"
    },
    {
        "question": "Which command is used to start Hadoop services in a cluster?",
        "options": [
            "start-dfs.sh",
            "hadoop-start",
            "hdfs-run.sh",
            "init-hadoop.sh"
        ],
        "answer": "start-dfs.sh"
    },
    {
        "question": "Which component is responsible for scheduling jobs in a Hadoop cluster?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "ResourceManager",
            "HDFS"
        ],
        "answer": "ResourceManager"
    },
    {
        "question": "In Hadoop, what is the purpose of setting up SSH password-less login?",
        "options": [
            "Secure communication between nodes",
            "Allow multiple users on the cluster",
            "Reduce the need for authentication",
            "Enable YARN execution"
        ],
        "answer": "Secure communication between nodes"
    },
    {
        "question": "Which of the following is NOT a Hadoop configuration file?",
        "options": [
            "hdfs-site.xml",
            "mapred-site.xml",
            "core-site.xml",
            "hadoop-env.sh"
        ],
        "answer": "hadoop-env.sh"
    },
    {
        "question": "Which environment variable must be set before running Hadoop?",
        "options": [
            "JAVA_HOME",
            "HADOOP_PATH",
            "CLASSPATH",
            "YARN_HOME"
        ],
        "answer": "JAVA_HOME"
    },
    {
        "question": "Which tool can be used for monitoring Hadoop cluster performance?",
        "options": [
            "Ganglia",
            "Nagios",
            "Prometheus",
            "All of the above"
        ],
        "answer": "All of the above"
    },
    {
        "question": "What is the role of Secondary NameNode in Hadoop?",
        "options": [
            "Takes over when NameNode fails",
            "Stores a backup of NameNode metadata",
            "Handles job scheduling",
            "Processes MapReduce tasks"
        ],
        "answer": "Stores a backup of NameNode metadata"
    },
    {
        "question": "Which command lists all files in HDFS?",
        "options": [
            "hdfs dfs -ls /",
            "hadoop ls",
            "hdfs list",
            "hdfs file -ls"
        ],
        "answer": "hdfs dfs -ls /"
    },
    {
        "question": "What is the purpose of the 'core-site.xml' file?",
        "options": [
            "Defines HDFS-related configurations",
            "Configures YARN settings",
            "Specifies core Hadoop parameters",
            "Sets up MapReduce jobs"
        ],
        "answer": "Specifies core Hadoop parameters"
    },
    {
        "question": "Which file in Hadoop configuration sets heap size limits?",
        "options": [
            "hadoop-env.sh",
            "yarn-site.xml",
            "mapred-site.xml",
            "hdfs-site.xml"
        ],
        "answer": "hadoop-env.sh"
    },
    {
        "question": "Which of the following services must be started first in a Hadoop cluster?",
        "options": [
            "YARN ResourceManager",
            "HDFS NameNode",
            "JobTracker",
            "Hadoop UI"
        ],
        "answer": "HDFS NameNode"
    },
    {
        "question": "Which of the following is a prerequisite before starting a Hadoop cluster?",
        "options": [
            "Format the NameNode",
            "Start the TaskTracker",
            "Run a MapReduce job",
            "Modify the YARN scheduler"
        ],
        "answer": "Format the NameNode"
    },
    {
        "question": "Which daemon process is responsible for running YARN applications?",
        "options": [
            "ResourceManager",
            "NodeManager",
            "JobTracker",
            "TaskTracker"
        ],
        "answer": "NodeManager"
    },
    {
        "question": "Which tool is commonly used for log analysis in Hadoop?",
        "options": [
            "Syslog",
            "Logstash",
            "Flume",
            "Nagios"
        ],
        "answer": "Flume"
    },
    {
        "question": "Which of the following is required for setting up a Hadoop cluster?",
        "options": [
            "Static IP configuration",
            "RAID storage",
            "VPN setup",
            "Cloud instance"
        ],
        "answer": "Static IP configuration"
    },
    {
        "question": "Which scheduler is responsible for resource allocation in Hadoop YARN?",
        "options": [
            "Fair Scheduler",
            "Capacity Scheduler",
            "FIFO Scheduler",
            "All of the above"
        ],
        "answer": "All of the above"
    },
    {
        "question": "Which configuration file sets up the ResourceManager for YARN?",
        "options": [
            "hdfs-site.xml",
            "mapred-site.xml",
            "core-site.xml",
            "yarn-site.xml"
        ],
        "answer": "yarn-site.xml"
    },
    {
        "question": "Which command is used to check the Hadoop cluster status?",
        "options": [
            "hdfs dfsadmin -report",
            "hadoop status",
            "hdfs check",
            "yarn status"
        ],
        "answer": "hdfs dfsadmin -report"
    },
    {
        "question": "Which of the following is NOT a component of a Hadoop cluster?",
        "options": [
            "NameNode",
            "DataNode",
            "TaskManager",
            "ResourceManager"
        ],
        "answer": "TaskManager"
    },
    {
        "question": "What is the default port number for the Hadoop NameNode web interface?",
        "options": [
            "8088",
            "50070",
            "8020",
            "9000"
        ],
        "answer": "50070"
    },
    {
        "question": "Which command is used to stop the Hadoop Distributed File System (HDFS)?",
        "options": [
            "stop-hdfs.sh",
            "stop-dfs.sh",
            "hdfs-stop.sh",
            "shutdown-hdfs.sh"
        ],
        "answer": "stop-dfs.sh"
    },
    {
        "question": "Which file contains Hadoop environment variables such as heap size and Java home path?",
        "options": [
            "hadoop-env.sh",
            "core-site.xml",
            "mapred-site.xml",
            "hdfs-site.xml"
        ],
        "answer": "hadoop-env.sh"
    },
    {
        "question": "Which process handles client requests and metadata operations in an HDFS cluster?",
        "options": [
            "ResourceManager",
            "DataNode",
            "TaskTracker",
            "NameNode"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What is the primary role of a DataNode in Hadoop?",
        "options": [
            "Manages metadata",
            "Stores actual data blocks",
            "Schedules jobs",
            "Handles cluster configuration"
        ],
        "answer": "Stores actual data blocks"
    },
    {
        "question": "Which of the following is NOT a valid Hadoop cluster mode?",
        "options": [
            "Standalone Mode",
            "Pseudo-Distributed Mode",
            "Hybrid Mode",
            "Fully Distributed Mode"
        ],
        "answer": "Hybrid Mode"
    },
    {
        "question": "Which property in 'hdfs-site.xml' is used to specify the replication factor?",
        "options": [
            "dfs.replication",
            "hdfs.replication.factor",
            "dfs.blocksize",
            "hdfs.cluster.size"
        ],
        "answer": "dfs.replication"
    },
    {
        "question": "Which of the following best describes a Hadoop cluster?",
        "options": [
            "A single computer processing big data",
            "A group of networked servers working together",
            "A single-node database server",
            "A cloud-based file storage system"
        ],
        "answer": "A group of networked servers working together"
    },
    {
        "question": "What is the function of 'fs.defaultFS' in Hadoop configuration?",
        "options": [
            "Defines the default file system URI",
            "Specifies block replication factor",
            "Sets memory limits",
            "Manages YARN settings"
        ],
        "answer": "Defines the default file system URI"
    },
    {
        "question": "Which process in Hadoop periodically merges and compacts the edit logs?",
        "options": [
            "JobTracker",
            "TaskTracker",
            "Secondary NameNode",
            "DataNode"
        ],
        "answer": "Secondary NameNode"
    },
    {
        "question": "Which of the following is NOT a daemon in Hadoop?",
        "options": [
            "NameNode",
            "DataNode",
            "ZooKeeper",
            "TaskTracker"
        ],
        "answer": "ZooKeeper"
    },
    {
        "question": "Which component in Hadoop is responsible for splitting input data for processing?",
        "options": [
            "Reducer",
            "Mapper",
            "JobTracker",
            "HDFS"
        ],
        "answer": "Mapper"
    },
    {
        "question": "Which file system is used by Hadoop to store large files across multiple machines?",
        "options": [
            "Ext4",
            "HDFS",
            "ZFS",
            "Btrfs"
        ],
        "answer": "HDFS"
    },
    {
        "question": "Which of the following commands is used to start the YARN ResourceManager?",
        "options": [
            "start-yarn.sh",
            "yarn-daemon.sh start resourcemanager",
            "yarn start",
            "hadoop-yarn.sh"
        ],
        "answer": "yarn-daemon.sh start resourcemanager"
    },
    {
        "question": "Which scheduler allows users to specify the minimum and maximum resources for applications?",
        "options": [
            "FIFO Scheduler",
            "Fair Scheduler",
            "Capacity Scheduler",
            "Task Scheduler"
        ],
        "answer": "Capacity Scheduler"
    },
    {
        "question": "What is the role of the 'hadoop.tmp.dir' configuration parameter?",
        "options": [
            "Stores temporary files used by Hadoop",
            "Specifies the directory for storing logs",
            "Sets default permissions",
            "Controls YARN job scheduling"
        ],
        "answer": "Stores temporary files used by Hadoop"
    },
    {
        "question": "Which tool is used to manage Hadoop cluster logs?",
        "options": [
            "Log4j",
            "Flume",
            "Nagios",
            "Zookeeper"
        ],
        "answer": "Log4j"
    },
    {
        "question": "Which Hadoop component is responsible for resource allocation?",
        "options": [
            "NameNode",
            "DataNode",
            "YARN ResourceManager",
            "TaskTracker"
        ],
        "answer": "YARN ResourceManager"
    },
    {
        "question": "Which of the following command is used to list all files in HDFS?",
        "options": [
            "hdfs dfs -ls /",
            "hadoop fs -list",
            "yarn file -list",
            "hdfs -show"
        ],
        "answer": "hdfs dfs -ls /"
    },
    {
        "question": "Which file in Hadoop specifies the YARN configuration settings?",
        "options": [
            "yarn-site.xml",
            "mapred-site.xml",
            "hdfs-site.xml",
            "core-site.xml"
        ],
        "answer": "yarn-site.xml"
    },
    {
        "question": "Which command checks the status of the Hadoop NameNode?",
        "options": [
            "hdfs dfsadmin -report",
            "hdfs status",
            "hadoop check",
            "yarn info"
        ],
        "answer": "hdfs dfsadmin -report"
    },
    {
        "question": "Which of the following tools is used to transfer logs to Hadoop?",
        "options": [
            "Flume",
            "Kafka",
            "Sqoop",
            "Zookeeper"
        ],
        "answer": "Flume"
    },
    {
        "question": "Which setting controls the maximum memory allocation for YARN applications?",
        "options": [
            "yarn.nodemanager.resource.memory-mb",
            "hdfs.max.memory",
            "mapred.max.memory",
            "core.memory.limit"
        ],
        "answer": "yarn.nodemanager.resource.memory-mb"
    },
    {
        "question": "Which configuration file is used to modify MapReduce settings?",
        "options": [
            "mapred-site.xml",
            "hdfs-site.xml",
            "yarn-site.xml",
            "core-site.xml"
        ],
        "answer": "mapred-site.xml"
    },
    {
        "question": "What is the role of a Checkpoint in Hadoop?",
        "options": [
            "Reduces edit log size",
            "Increases block replication",
            "Speeds up MapReduce jobs",
            "Deletes old HDFS files"
        ],
        "answer": "Reduces edit log size"
    },
    {
        "question": "Which directory stores the Hadoop NameNode metadata?",
        "options": [
            "/var/hadoop/metadata",
            "/hadoop/nn-meta",
            "/data/hadoop/nn",
            "/hadoop/dfs/name"
        ],
        "answer": "/hadoop/dfs/name"
    },
    {
        "question": "Which daemon process runs on worker nodes in Hadoop?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "Secondary NameNode"
        ],
        "answer": "DataNode"
    },
    {
        "question": "Which Hadoop daemon helps in balancing data across DataNodes?",
        "options": [
            "Balancer",
            "TaskTracker",
            "ResourceManager",
            "BlockManager"
        ],
        "answer": "Balancer"
    },
    {
        "question": "Which command lists active Hadoop jobs?",
        "options": [
            "hadoop job -list",
            "yarn application -list",
            "hdfs jobs -status",
            "mapred jobs -running"
        ],
        "answer": "yarn application -list"
    },
    {
        "question": "Which authentication method is commonly used in Hadoop for secure user access?",
        "options": [
            "Kerberos",
            "OAuth",
            "JWT",
            "SAML"
        ],
        "answer": "Kerberos"
    },
    {
        "question": "What is the primary function of Kerberos in Hadoop security?",
        "options": [
            "Encrypting data at rest",
            "Managing user authentication",
            "Handling access control",
            "Monitoring cluster activity"
        ],
        "answer": "Managing user authentication"
    },
    {
        "question": "Which of the following is NOT a Hadoop security feature?",
        "options": [
            "Encryption",
            "Access Control Lists (ACLs)",
            "Load Balancing",
            "Auditing"
        ],
        "answer": "Load Balancing"
    },
    {
        "question": "Which component in Hadoop is responsible for authorizing users and groups?",
        "options": [
            "ResourceManager",
            "NameNode",
            "Ranger",
            "DataNode"
        ],
        "answer": "Ranger"
    },
    {
        "question": "Which security framework is commonly integrated with Hadoop for role-based access control?",
        "options": [
            "Apache Ranger",
            "Apache Spark",
            "Apache Kafka",
            "Apache Storm"
        ],
        "answer": "Apache Ranger"
    },
    {
        "question": "What does Hadoop use to encrypt data during transmission?",
        "options": [
            "SSL/TLS",
            "AES",
            "RSA",
            "SHA-256"
        ],
        "answer": "SSL/TLS"
    },
    {
        "question": "Which authentication mechanism allows users to access Hadoop services using their organizational credentials?",
        "options": [
            "Kerberos",
            "LDAP",
            "OAuth",
            "SAML"
        ],
        "answer": "LDAP"
    },
    {
        "question": "Which protocol does Hadoop use for user authentication when integrated with Kerberos?",
        "options": [
            "HTTP",
            "SPNEGO",
            "LDAP",
            "SSL"
        ],
        "answer": "SPNEGO"
    },
    {
        "question": "Which tool is used to monitor security events in a Hadoop cluster?",
        "options": [
            "Cloudera Manager",
            "Prometheus",
            "Apache Spark",
            "Apache Ranger"
        ],
        "answer": "Apache Ranger"
    },
    {
        "question": "What is the primary purpose of configuring ACLs in Hadoop?",
        "options": [
            "Controlling network traffic",
            "Restricting unauthorized access",
            "Improving data compression",
            "Reducing disk usage"
        ],
        "answer": "Restricting unauthorized access"
    },
    {
        "question": "Which file must be configured to enable Kerberos authentication in Hadoop?",
        "options": [
            "krb5.conf",
            "core-site.xml",
            "hdfs-site.xml",
            "mapred-site.xml"
        ],
        "answer": "krb5.conf"
    },
    {
        "question": "What does 'Sentry' provide in Hadoop security?",
        "options": [
            "Fine-grained access control",
            "Log analysis",
            "Job scheduling",
            "Data replication"
        ],
        "answer": "Fine-grained access control"
    },
    {
        "question": "Which of the following is NOT an encryption method used in Hadoop?",
        "options": [
            "HDFS Transparent Encryption",
            "SSL/TLS",
            "OAuth Encryption",
            "Kerberos Encryption"
        ],
        "answer": "OAuth Encryption"
    },
    {
        "question": "Which component in Hadoop can be used to enforce access policies across multiple services?",
        "options": [
            "Apache Knox",
            "Apache Hive",
            "Apache Tez",
            "Apache Kafka"
        ],
        "answer": "Apache Knox"
    },
    {
        "question": "What is the role of 'spnego-authentication' in Hadoop?",
        "options": [
            "Provides job scheduling",
            "Encrypts stored data",
            "Handles Kerberos authentication over HTTP",
            "Monitors cluster health"
        ],
        "answer": "Handles Kerberos authentication over HTTP"
    },
    {
        "question": "What type of security does LDAP provide in a Hadoop cluster?",
        "options": [
            "Authentication",
            "Authorization",
            "Encryption",
            "Load Balancing"
        ],
        "answer": "Authentication"
    },
    {
        "question": "Which Hadoop component is responsible for storing Kerberos keytabs?",
        "options": [
            "ResourceManager",
            "NameNode",
            "DataNode",
            "Key Distribution Center (KDC)"
        ],
        "answer": "Key Distribution Center (KDC)"
    },
    {
        "question": "What is the primary advantage of using Apache Ranger with Hadoop?",
        "options": [
            "Provides centralized security administration",
            "Increases storage capacity",
            "Enhances query speed",
            "Optimizes MapReduce tasks"
        ],
        "answer": "Provides centralized security administration"
    },
    {
        "question": "Which of the following is a benefit of using Hadoop with Kerberos?",
        "options": [
            "Prevents unauthorized access",
            "Improves query execution time",
            "Enhances data compression",
            "Optimizes resource allocation"
        ],
        "answer": "Prevents unauthorized access"
    },
    {
        "question": "Which command is used to check Kerberos ticket status in Hadoop?",
        "options": [
            "klist",
            "ktab",
            "kinit",
            "kdestroy"
        ],
        "answer": "klist"
    },
    {
        "question": "What does Apache Knox provide in a secured Hadoop environment?",
        "options": [
            "Gateway security",
            "Data encryption",
            "Distributed processing",
            "Metadata storage"
        ],
        "answer": "Gateway security"
    },
    {
        "question": "What type of security risk does LDAP integration mitigate in Hadoop?",
        "options": [
            "Brute force attacks",
            "Data corruption",
            "Storage failure",
            "Network latency"
        ],
        "answer": "Brute force attacks"
    },
    {
        "question": "Which feature does HDFS Transparent Encryption provide?",
        "options": [
            "Encrypts data at rest",
            "Encrypts network traffic",
            "Authenticates users",
            "Optimizes MapReduce jobs"
        ],
        "answer": "Encrypts data at rest"
    },
    {
        "question": "Which component in Hadoop security is responsible for managing keys for encryption?",
        "options": [
            "Hadoop KMS (Key Management Server)",
            "YARN NodeManager",
            "Apache Hive",
            "Zookeeper"
        ],
        "answer": "Hadoop KMS (Key Management Server)"
    },
    {
        "question": "Which security feature allows encryption of individual Hadoop files?",
        "options": [
            "HDFS Transparent Encryption",
            "ACLs",
            "Role-Based Access Control",
            "Kerberos Tokens"
        ],
        "answer": "HDFS Transparent Encryption"
    },
    {
        "question": "Which of the following is NOT a best practice for securing a Hadoop cluster?",
        "options": [
            "Disabling Kerberos authentication",
            "Using firewall rules",
            "Configuring audit logging",
            "Encrypting sensitive data"
        ],
        "answer": "Disabling Kerberos authentication"
    },
    {
        "question": "Which Hadoop service logs security-related activities?",
        "options": [
            "Audit Logs",
            "MapReduce",
            "DataNode",
            "YARN Scheduler"
        ],
        "answer": "Audit Logs"
    },
    {
        "question": "What is the function of 'hadoop.security.authentication' in Hadoop security?",
        "options": [
            "Specifies the authentication method",
            "Encrypts data blocks",
            "Optimizes HDFS storage",
            "Improves job scheduling"
        ],
        "answer": "Specifies the authentication method"
    },
    {
        "question": "Which attack does enabling Kerberos authentication in Hadoop help prevent?",
        "options": [
            "Man-in-the-middle attack",
            "SQL injection",
            "Cross-site scripting",
            "Denial-of-Service (DoS)"
        ],
        "answer": "Man-in-the-middle attack"
    },
    {
        "question": "What does 'hadoop.security.authorization' control in Hadoop?",
        "options": [
            "User permissions",
            "Block replication",
            "Job scheduling",
            "Data compression"
        ],
        "answer": "User permissions"
    },
    {
        "question": "Which Hadoop component enables fine-grained access control?",
        "options": [
            "Apache Ranger",
            "Apache Hive",
            "Apache Mahout",
            "Apache Storm"
        ],
        "answer": "Apache Ranger"
    },
    {
        "question": "Which security feature in Hadoop ensures that only authorized users can access cluster resources?",
        "options": [
            "Authentication",
            "Compression",
            "Replication",
            "Load balancing"
        ],
        "answer": "Authentication"
    },
    {
        "question": "Which tool is used to enforce fine-grained access policies in Hadoop?",
        "options": [
            "Apache Ranger",
            "Apache Flume",
            "Apache HBase",
            "Apache Spark"
        ],
        "answer": "Apache Ranger"
    },
    {
        "question": "Which component in Hadoop is responsible for enforcing authentication using Kerberos?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "Key Distribution Center (KDC)"
        ],
        "answer": "Key Distribution Center (KDC)"
    },
    {
        "question": "What is the primary role of Apache Knox in Hadoop security?",
        "options": [
            "Provides a secure gateway",
            "Encrypts HDFS data",
            "Manages cluster resources",
            "Monitors system logs"
        ],
        "answer": "Provides a secure gateway"
    },
    {
        "question": "Which of the following does Hadoop use for role-based access control?",
        "options": [
            "Apache Sentry",
            "Apache Kafka",
            "Apache Flink",
            "Apache Tez"
        ],
        "answer": "Apache Sentry"
    },
    {
        "question": "Which command initializes a Kerberos ticket for authentication in Hadoop?",
        "options": [
            "kinit",
            "ktutil",
            "kadmin",
            "klist"
        ],
        "answer": "kinit"
    },
    {
        "question": "Which of the following security threats is addressed by using Hadoop Kerberos authentication?",
        "options": [
            "Unauthorized access",
            "Data redundancy",
            "Job scheduling inefficiencies",
            "Storage failures"
        ],
        "answer": "Unauthorized access"
    },
    {
        "question": "What is the purpose of a Hadoop Key Management Server (KMS)?",
        "options": [
            "Stores encryption keys securely",
            "Optimizes cluster performance",
            "Manages job scheduling",
            "Improves MapReduce execution"
        ],
        "answer": "Stores encryption keys securely"
    },
    {
        "question": "Which encryption method does Hadoop use for protecting data in motion?",
        "options": [
            "SSL/TLS",
            "AES-256",
            "RSA",
            "SHA-512"
        ],
        "answer": "SSL/TLS"
    },
    {
        "question": "Which Hadoop component is responsible for access control at the file level?",
        "options": [
            "HDFS ACLs",
            "YARN ResourceManager",
            "HBase",
            "ZooKeeper"
        ],
        "answer": "HDFS ACLs"
    },
    {
        "question": "Which security model is used in Hadoop to control access to cluster resources?",
        "options": [
            "Discretionary Access Control (DAC)",
            "Mandatory Access Control (MAC)",
            "Role-Based Access Control (RBAC)",
            "Attribute-Based Access Control (ABAC)"
        ],
        "answer": "Role-Based Access Control (RBAC)"
    },
    {
        "question": "Which configuration file in Hadoop contains security-related settings?",
        "options": [
            "core-site.xml",
            "mapred-site.xml",
            "hdfs-site.xml",
            "yarn-site.xml"
        ],
        "answer": "core-site.xml"
    },
    {
        "question": "What is the primary purpose of enabling audit logs in Hadoop?",
        "options": [
            "Track user activities",
            "Improve data compression",
            "Reduce job execution time",
            "Optimize block replication"
        ],
        "answer": "Track user activities"
    },
    {
        "question": "Which of the following is a security risk in Hadoop when Kerberos is not enabled?",
        "options": [
            "Unauthorized access",
            "Data loss due to replication",
            "Reduced query performance",
            "Job scheduling inefficiency"
        ],
        "answer": "Unauthorized access"
    },
    {
        "question": "Which authentication method is used to integrate Hadoop with enterprise user directories?",
        "options": [
            "LDAP",
            "OAuth",
            "JWT",
            "SAML"
        ],
        "answer": "LDAP"
    },
    {
        "question": "Which of the following provides encryption for Hadoop data stored on HDFS?",
        "options": [
            "HDFS Transparent Encryption",
            "YARN ACLs",
            "MapReduce Framework",
            "Apache Tez"
        ],
        "answer": "HDFS Transparent Encryption"
    },
    {
        "question": "Which command is used to destroy a Kerberos ticket in Hadoop?",
        "options": [
            "kdestroy",
            "kinit",
            "klist",
            "ktutil"
        ],
        "answer": "kdestroy"
    },
    {
        "question": "Which of the following security frameworks allows fine-grained access control for Hive, HBase, and HDFS?",
        "options": [
            "Apache Ranger",
            "Apache Storm",
            "Apache Spark",
            "Apache Mahout"
        ],
        "answer": "Apache Ranger"
    },
    {
        "question": "What is the main security advantage of integrating Hadoop with Active Directory via LDAP?",
        "options": [
            "Centralized user authentication",
            "Increased job scheduling efficiency",
            "Faster query execution",
            "Improved data compression"
        ],
        "answer": "Centralized user authentication"
    },
    {
        "question": "Which of the following helps secure communication between Hadoop services?",
        "options": [
            "SSL/TLS",
            "MapReduce",
            "JobTracker",
            "TaskTracker"
        ],
        "answer": "SSL/TLS"
    },
    {
        "question": "What is a primary function of Apache Knox?",
        "options": [
            "Provides a secure REST API gateway",
            "Manages Hadoop cluster resources",
            "Optimizes MapReduce performance",
            "Monitors job execution time"
        ],
        "answer": "Provides a secure REST API gateway"
    },
    {
        "question": "Which Hadoop security feature ensures that data stored in HDFS cannot be accessed by unauthorized users?",
        "options": [
            "HDFS ACLs",
            "Hadoop NameNode",
            "DataNode Replication",
            "JobTracker"
        ],
        "answer": "HDFS ACLs"
    },
    {
        "question": "Which of the following is a major security risk in Hadoop clusters?",
        "options": [
            "Unauthorized access to data",
            "Job execution failures",
            "Block replication issues",
            "Network latency"
        ],
        "answer": "Unauthorized access to data"
    },
    {
        "question": "Which Apache project is used to encrypt sensitive data in Hadoop?",
        "options": [
            "Apache Ranger",
            "Apache Knox",
            "Apache Sentry",
            "Apache Kafka"
        ],
        "answer": "Apache Ranger"
    },
    {
        "question": "What is the function of 'hadoop.security.group.mapping'?",
        "options": [
            "Maps user groups for access control",
            "Encrypts stored data",
            "Manages MapReduce jobs",
            "Optimizes cluster performance"
        ],
        "answer": "Maps user groups for access control"
    },
    {
        "question": "Which feature allows Hadoop administrators to set permissions on HDFS files and directories?",
        "options": [
            "Access Control Lists (ACLs)",
            "Replication Factor",
            "YARN Job Scheduler",
            "Task Tracker"
        ],
        "answer": "Access Control Lists (ACLs)"
    },
    {
        "question": "Which protocol is used for secure authentication in Hadoop Web UIs?",
        "options": [
            "SPNEGO",
            "OAuth",
            "JWT",
            "SAML"
        ],
        "answer": "SPNEGO"
    },
    {
        "question": "Which encryption mechanism is used to protect HDFS data at rest?",
        "options": [
            "HDFS Transparent Encryption",
            "SSL/TLS",
            "RSA",
            "AES-512"
        ],
        "answer": "HDFS Transparent Encryption"
    },
    {
        "question": "Which of the following Hadoop security tools helps in role-based access control?",
        "options": [
            "Apache Sentry",
            "Apache Storm",
            "Apache Kafka",
            "Apache Spark"
        ],
        "answer": "Apache Sentry"
    },
    {
        "question": "Which Hadoop command is used to add a new DataNode to an existing cluster?",
        "options": [
            "hdfs dfsadmin -refreshNodes",
            "hadoop balancer",
            "hdfs namenode -format",
            "hdfs dfs -copyFromLocal"
        ],
        "answer": "hdfs dfsadmin -refreshNodes"
    },
    {
        "question": "What is the primary purpose of Hadoop balancer?",
        "options": [
            "Rebalancing data across DataNodes",
            "Monitoring cluster health",
            "Encrypting stored data",
            "Optimizing MapReduce jobs"
        ],
        "answer": "Rebalancing data across DataNodes"
    },
    {
        "question": "Which tool is used to monitor Hadoop cluster health and performance?",
        "options": [
            "Apache Ambari",
            "Apache Spark",
            "Apache HBase",
            "Apache Tez"
        ],
        "answer": "Apache Ambari"
    },
    {
        "question": "What is the function of 'hdfs fsck' in Hadoop?",
        "options": [
            "Checks file system health",
            "Formats the HDFS",
            "Deletes corrupted files",
            "Monitors MapReduce jobs"
        ],
        "answer": "Checks file system health"
    },
    {
        "question": "Which of the following is a valid Hadoop benchmarking tool?",
        "options": [
            "TestDFSIO",
            "SparkBench",
            "TeraGen",
            "All of the above"
        ],
        "answer": "All of the above"
    },
    {
        "question": "Which command removes a DataNode from an active cluster?",
        "options": [
            "hdfs dfsadmin -decommissionNode",
            "hdfs dfs -rm",
            "hdfs namenode -format",
            "hdfs dfsadmin -report"
        ],
        "answer": "hdfs dfsadmin -decommissionNode"
    },
    {
        "question": "What does the 'hdfs dfsadmin -report' command display?",
        "options": [
            "Cluster storage usage and node status",
            "MapReduce job execution details",
            "HBase table metadata",
            "Hadoop security logs"
        ],
        "answer": "Cluster storage usage and node status"
    },
    {
        "question": "Which component handles the automatic re-replication of missing HDFS blocks?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "YARN NodeManager"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What is the primary function of a Secondary NameNode in Hadoop?",
        "options": [
            "Merges fsimage and edits log",
            "Handles client requests",
            "Stores replica data",
            "Manages job execution"
        ],
        "answer": "Merges fsimage and edits log"
    },
    {
        "question": "Which Hadoop command is used to transfer data between clusters?",
        "options": [
            "DistCp",
            "CopyFromLocal",
            "MoveToTrash",
            "Fsck"
        ],
        "answer": "DistCp"
    },
    {
        "question": "Which metric is commonly used to measure Hadoop performance?",
        "options": [
            "Job execution time",
            "Disk fragmentation",
            "CPU voltage",
            "Internet speed"
        ],
        "answer": "Job execution time"
    },
    {
        "question": "What does the TeraSort benchmark measure in Hadoop?",
        "options": [
            "Sorting performance of HDFS",
            "Cluster network speed",
            "File system replication time",
            "MapReduce failure rates"
        ],
        "answer": "Sorting performance of HDFS"
    },
    {
        "question": "Which component in Hadoop manages resource allocation for jobs?",
        "options": [
            "YARN ResourceManager",
            "DataNode",
            "TaskTracker",
            "HDFS Namenode"
        ],
        "answer": "YARN ResourceManager"
    },
    {
        "question": "Which process is responsible for storing the metadata of HDFS?",
        "options": [
            "NameNode",
            "DataNode",
            "ResourceManager",
            "NodeManager"
        ],
        "answer": "NameNode"
    },
    {
        "question": "Which of the following is a valid reason for cluster rebalancing in Hadoop?",
        "options": [
            "Uneven data distribution",
            "Excessive CPU usage",
            "Low network bandwidth",
            "Excessive number of NameNodes"
        ],
        "answer": "Uneven data distribution"
    },
    {
        "question": "Which Hadoop tool helps in cluster configuration management and monitoring?",
        "options": [
            "Apache Ambari",
            "Apache HBase",
            "Apache Mahout",
            "Apache Kafka"
        ],
        "answer": "Apache Ambari"
    },
    {
        "question": "What is the function of 'dfsadmin -safemode leave' in Hadoop?",
        "options": [
            "Exits safe mode and allows writes",
            "Deletes files in HDFS",
            "Restarts the NameNode",
            "Optimizes block replication"
        ],
        "answer": "Exits safe mode and allows writes"
    },
    {
        "question": "Which parameter is used to increase the replication factor of a file in HDFS?",
        "options": [
            "dfs.replication",
            "dfs.blocksize",
            "mapreduce.inputformat",
            "yarn.nodemanager.resource.memory"
        ],
        "answer": "dfs.replication"
    },
    {
        "question": "Which benchmark test is commonly used for measuring disk I/O performance in Hadoop?",
        "options": [
            "TestDFSIO",
            "TeraGen",
            "WordCount",
            "ShuffleSort"
        ],
        "answer": "TestDFSIO"
    },
    {
        "question": "Which process occurs first when a new node is added to a Hadoop cluster?",
        "options": [
            "Replication balancing",
            "Job scheduling",
            "MapReduce execution",
            "HDFS file cleanup"
        ],
        "answer": "Replication balancing"
    },
    {
        "question": "Which command lists all active DataNodes in a Hadoop cluster?",
        "options": [
            "hdfs dfsadmin -report",
            "hadoop namenode -format",
            "hdfs balancer -start",
            "yarn top"
        ],
        "answer": "hdfs dfsadmin -report"
    },
    {
        "question": "Which mechanism helps optimize data locality in Hadoop?",
        "options": [
            "Rack awareness",
            "Load balancing",
            "NameNode failover",
            "Secondary NameNode"
        ],
        "answer": "Rack awareness"
    },
    {
        "question": "Which command is used to start the Hadoop balancer?",
        "options": [
            "hdfs balancer",
            "yarn rmadmin -refreshNodes",
            "hadoop fsck",
            "hdfs dfs -du"
        ],
        "answer": "hdfs balancer"
    },
    {
        "question": "Which Hadoop metric indicates network performance issues?",
        "options": [
            "Slow block transfers",
            "High CPU usage",
            "Low heap size",
            "High file replication"
        ],
        "answer": "Slow block transfers"
    },
    {
        "question": "What does 'DistCp' in Hadoop stand for?",
        "options": [
            "Distributed Copy",
            "Distributed Compression",
            "Data Compression",
            "Disk Cleanup"
        ],
        "answer": "Distributed Copy"
    },
    {
        "question": "Which method is used to remove a failed DataNode from an active Hadoop cluster?",
        "options": [
            "Decommissioning",
            "Replication",
            "Balancing",
            "Formatting"
        ],
        "answer": "Decommissioning"
    },
    {
        "question": "Which of the following indicates a healthy Hadoop cluster?",
        "options": [
            "Low under-replicated blocks",
            "High CPU utilization",
            "Increased heap memory usage",
            "Excessive number of log files"
        ],
        "answer": "Low under-replicated blocks"
    },
    {
        "question": "Which Apache project provides a web-based interface for Hadoop cluster monitoring?",
        "options": [
            "Apache Ambari",
            "Apache Zookeeper",
            "Apache Tez",
            "Apache Mahout"
        ],
        "answer": "Apache Ambari"
    },
    {
        "question": "What is the main function of the NameNode in Hadoop?",
        "options": [
            "Stores metadata",
            "Stores data blocks",
            "Runs MapReduce jobs",
            "Manages YARN resources"
        ],
        "answer": "Stores metadata"
    },
    {
        "question": "Which command checks the health of an HDFS cluster?",
        "options": [
            "hdfs fsck",
            "hdfs dfs -ls",
            "hdfs balancer",
            "hadoop jar"
        ],
        "answer": "hdfs fsck"
    },
    {
        "question": "Which component stores actual data in HDFS?",
        "options": [
            "DataNode",
            "NameNode",
            "Secondary NameNode",
            "ResourceManager"
        ],
        "answer": "DataNode"
    },
    {
        "question": "Which Hadoop command displays a report of active nodes?",
        "options": [
            "hdfs dfsadmin -report",
            "hdfs balancer",
            "hdfs dfs -du",
            "yarn top"
        ],
        "answer": "hdfs dfsadmin -report"
    },
    {
        "question": "Which process ensures that all DataNodes have balanced storage?",
        "options": [
            "HDFS Balancer",
            "MapReduce",
            "YARN Scheduler",
            "HDFS Formatter"
        ],
        "answer": "HDFS Balancer"
    },
    {
        "question": "Which command copies a file from the local system to HDFS?",
        "options": [
            "hdfs dfs -copyFromLocal",
            "hdfs dfs -rm",
            "hdfs dfs -ls",
            "hdfs fsck"
        ],
        "answer": "hdfs dfs -copyFromLocal"
    },
    {
        "question": "Which command is used to remove a DataNode from a Hadoop cluster?",
        "options": [
            "hdfs dfsadmin -refreshNodes",
            "hdfs dfs -rm",
            "hadoop jar",
            "hdfs balancer"
        ],
        "answer": "hdfs dfsadmin -refreshNodes"
    },
    {
        "question": "What does 'DistCp' do in Hadoop?",
        "options": [
            "Copies data between clusters",
            "Compresses HDFS files",
            "Deletes old logs",
            "Formats NameNode"
        ],
        "answer": "Copies data between clusters"
    },
    {
        "question": "Which tool provides a web interface for monitoring Hadoop clusters?",
        "options": [
            "Apache Ambari",
            "Apache HBase",
            "Apache Pig",
            "Apache Flume"
        ],
        "answer": "Apache Ambari"
    },
    {
        "question": "What is the default replication factor in HDFS?",
        "options": [
            "3",
            "1",
            "2",
            "4"
        ],
        "answer": "3"
    },
    {
        "question": "Which Hadoop component merges metadata logs with fsimage?",
        "options": [
            "Secondary NameNode",
            "DataNode",
            "JobTracker",
            "TaskTracker"
        ],
        "answer": "Secondary NameNode"
    },
    {
        "question": "What is the purpose of Hadoop balancer?",
        "options": [
            "Redistributes data evenly",
            "Deletes corrupted files",
            "Monitors network traffic",
            "Runs MapReduce jobs"
        ],
        "answer": "Redistributes data evenly"
    },
    {
        "question": "Which command lists files in an HDFS directory?",
        "options": [
            "hdfs dfs -ls",
            "hdfs dfs -rm",
            "hdfs dfs -copyFromLocal",
            "hdfs fsck"
        ],
        "answer": "hdfs dfs -ls"
    },
    {
        "question": "Which command decommissions a DataNode?",
        "options": [
            "hdfs dfsadmin -decommissionNode",
            "hdfs dfs -rm",
            "hadoop balancer",
            "yarn rmadmin"
        ],
        "answer": "hdfs dfsadmin -decommissionNode"
    },
    {
        "question": "What is a block in HDFS?",
        "options": [
            "A fixed-size data chunk",
            "A process scheduling unit",
            "A network request",
            "A file format"
        ],
        "answer": "A fixed-size data chunk"
    },
    {
        "question": "Which command is used to delete files from HDFS?",
        "options": [
            "hdfs dfs -rm",
            "hdfs dfs -ls",
            "hdfs balancer",
            "hadoop jar"
        ],
        "answer": "hdfs dfs -rm"
    },
    {
        "question": "What does 'hdfs dfsadmin -report' show?",
        "options": [
            "Cluster storage and node status",
            "List of running jobs",
            "Job execution time",
            "YARN resource usage"
        ],
        "answer": "Cluster storage and node status"
    },
    {
        "question": "What does Hadoop use to ensure high availability?",
        "options": [
            "Multiple NameNodes",
            "Single NameNode",
            "Multiple JobTrackers",
            "YARN ResourceManager"
        ],
        "answer": "Multiple NameNodes"
    },
    {
        "question": "Which command moves a file within HDFS?",
        "options": [
            "hdfs dfs -mv",
            "hdfs dfs -copyFromLocal",
            "hdfs balancer",
            "hdfs fsck"
        ],
        "answer": "hdfs dfs -mv"
    },
    {
        "question": "What does a 'heartbeat' signal in Hadoop indicate?",
        "options": [
            "DataNode is alive",
            "Job execution status",
            "Cluster is idle",
            "NameNode shutdown"
        ],
        "answer": "DataNode is alive"
    },
    {
        "question": "Which component is responsible for tracking block locations in HDFS?",
        "options": [
            "NameNode",
            "DataNode",
            "Secondary NameNode",
            "JobTracker"
        ],
        "answer": "NameNode"
    },
    {
        "question": "What happens when a NameNode fails in a high-availability Hadoop cluster?",
        "options": [
            "A standby NameNode takes over",
            "Cluster shuts down",
            "All jobs are lost",
            "HDFS is reformatted"
        ],
        "answer": "A standby NameNode takes over"
    },
    {
        "question": "Which tool is commonly used to benchmark Hadoop performance?",
        "options": [
            "TestDFSIO",
            "WordCount",
            "Pig",
            "Hive"
        ],
        "answer": "TestDFSIO"
    },
    {
        "question": "What does the 'dfs.replication' property control?",
        "options": [
            "Number of copies of a block",
            "File system format",
            "Data transfer rate",
            "YARN memory allocation"
        ],
        "answer": "Number of copies of a block"
    },
    {
        "question": "Which tool allows easy administration of a Hadoop cluster?",
        "options": [
            "Apache Ambari",
            "Apache Storm",
            "Apache Zookeeper",
            "Apache Kafka"
        ],
        "answer": "Apache Ambari"
    },
    {
        "question": "What does 'rack awareness' in Hadoop help with?",
        "options": [
            "Improving data locality",
            "Increasing file compression",
            "Reducing memory usage",
            "Enhancing encryption"
        ],
        "answer": "Improving data locality"
    },
    {
        "question": "Which command formats the NameNode?",
        "options": [
            "hdfs namenode -format",
            "hdfs balancer",
            "hdfs dfs -rm",
            "hdfs fsck"
        ],
        "answer": "hdfs namenode -format"
    },
    {
        "question": "What does a Secondary NameNode do?",
        "options": [
            "Combines fsimage and edits log",
            "Runs MapReduce jobs",
            "Stores actual data",
            "Manages YARN tasks"
        ],
        "answer": "Combines fsimage and edits log"
    },
    {
        "question": "Which process ensures lost data is automatically recovered in HDFS?",
        "options": [
            "Replication",
            "Sharding",
            "Partitioning",
            "Job scheduling"
        ],
        "answer": "Replication"
    }
]